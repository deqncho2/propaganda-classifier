{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout,Conv1D,MaxPooling1D,initializers,Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers,regularizers\n",
    "from keras.callbacks import History,EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from collections import namedtuple\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.models import doc2vec\n",
    "from gensim import models\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score,f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentences', 'article', 'N_sentence', 'is_propaganda', 'sadness', 'joy', 'fear', 'disgust', 'anger']\n"
     ]
    }
   ],
   "source": [
    "print(list(data.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(x):\n",
    " x=x.lower()\n",
    " tokenizer = RegexpTokenizer(r'\\w+')\n",
    " x=(tokenizer.tokenize(x))\n",
    " filtered_words =([word for word in x if word not in stopwords.words('english')])\n",
    " filtered_words=\" \".join(filtered_words)\n",
    " st = PorterStemmer()\n",
    " stemmed_words = ''.join(([st.stem(word) for word in filtered_words]))\n",
    " return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"new_sentences\"] = data[\"sentences\"].apply(lambda x: tokenise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_values=[]\n",
    "docs=[]\n",
    "i=0\n",
    "y= np.array([])\n",
    "for index, row in data.iterrows():\n",
    " w=row[\"new_sentences\"].split()\n",
    " word_value=row[\"new_sentences\"].split(\" \")\n",
    " t1=[i]\n",
    " all_tags=nltk.pos_tag(row[\"sentences\"].split())\n",
    " tag_values.append(all_tags)\n",
    " docs.append(TaggedDocument(words=w, tags=t1))\n",
    " if(row[\"is_propaganda\"]==\"propaganda\"):\n",
    "        y=np.append(y, 0)\n",
    " else:\n",
    "    y=np.append(y, 1)\n",
    " i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14263, 35)\n"
     ]
    }
   ],
   "source": [
    "#including grammatical features nouns, pronouns, etc\n",
    "pos_tags=['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP','TO','UH','VB','VBD','VBG','VBN','VBP','VBZ','WDT','WP','WP$','WRB']\n",
    "tagm = [[sum(sen,()).count(tag) for tag in pos_tags] for sen in tag_values]\n",
    "tagm=np.array(tagm)\n",
    "print(tagm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=10\n",
    "model = models.Doc2Vec(vector_size=size, window=3, min_count=2, workers=4, epochs=20)\n",
    "model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.train(docs, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(-1, 1)\n",
    "x=np.zeros((y.shape[0], size))\n",
    "for i in range(y.shape[0]):\n",
    "    x[i]=model[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27609899740587535\n",
      "0.7239010025941247\n"
     ]
    }
   ],
   "source": [
    "count_0=np.sum(y==0)\n",
    "count_1=np.sum(y==1)\n",
    "\n",
    "print(count_0/y.shape[0])\n",
    "print(count_1/y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14263, 51)\n"
     ]
    }
   ],
   "source": [
    "values=np.array(data.iloc[:,4:9])\n",
    "values2=np.array(data.iloc[:,2:3])\n",
    "x=np.append(x, values, axis=1)\n",
    "x=np.append(x, values2,axis=1)\n",
    "x=np.append(x, tagm,axis=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410, 51)\n",
      "(2853, 51)\n"
     ]
    }
   ],
   "source": [
    "split_index=int(y.shape[0]*0.8)\n",
    "y_train=y[0:split_index, :]\n",
    "x_train=x[0:split_index,:]\n",
    "y_val=y[split_index:,:]\n",
    "x_val=x[split_index:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "\n",
    "data_train= data.iloc[0:split_index,0:1]\n",
    "data_val=data.iloc[split_index:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28089395267309375\n",
      "0.7191060473269062\n"
     ]
    }
   ],
   "source": [
    "count_0_train=np.sum(y_train==0)\n",
    "count_1_train=np.sum(y_train==1)\n",
    "\n",
    "print(count_0_train/y_train.shape[0])\n",
    "print(count_1_train/y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25692253767963547\n",
      "0.7430774623203645\n"
     ]
    }
   ],
   "source": [
    "count_0=np.sum(y_val==0)\n",
    "count_1=np.sum(y_val==1)\n",
    "\n",
    "print(count_0/y_val.shape[0])\n",
    "print(count_1/y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.680821581280176\n",
      "Recall: 0.5717098226890684\n",
      "F1: 0.5653396669692063\n",
      "For validation \n",
      "\n",
      "Precision: 0.6653280330537124\n",
      "Recall: 0.5679798707817447\n",
      "F1: 0.5656317149886332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Using Logistic Regression as baseline\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_train=logReg.predict(x_train).reshape(-1,1)\n",
    "y_pred_val=logReg.predict(x_val).reshape(-1,1)\n",
    "\n",
    "train_recall=recall_score(y_train, y_pred_train, average=\"macro\")\n",
    "train_precision=precision_score(y_train,y_pred_train,average=\"macro\")\n",
    "train_f1=f1_score(y_train,y_pred_train,average=\"macro\")\n",
    "\n",
    "val_recall=recall_score(y_val, y_pred_val, average=\"macro\")\n",
    "val_precision=precision_score(y_val,y_pred_val,average=\"macro\")\n",
    "val_f1=f1_score(y_val,y_pred_val,average=\"macro\")\n",
    "\n",
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_precision))\n",
    "print(\"Recall: \"+str(train_recall))\n",
    "print(\"F1: \"+str(train_f1))\n",
    "\n",
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_precision))\n",
    "print(\"Recall: \"+str(val_recall))\n",
    "print(\"F1: \"+str(val_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.8150979276287147\n",
      "Recall: 0.8853065128089584\n",
      "F1: 0.8219652103978099\n",
      "For validation \n",
      "\n",
      "Precision: 0.5541095683137556\n",
      "Recall: 0.5690381348297253\n",
      "F1: 0.5440381917889026\n"
     ]
    }
   ],
   "source": [
    "#Using K-Nearest Neighbours\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_train=knn.predict(x_train).reshape(-1,1)\n",
    "y_pred_val=knn.predict(x_val).reshape(-1,1)\n",
    "\n",
    "train_recall=recall_score(y_train, y_pred_train, average=\"macro\")\n",
    "train_precision=precision_score(y_train,y_pred_train,average=\"macro\")\n",
    "train_f1=f1_score(y_train,y_pred_train,average=\"macro\")\n",
    "\n",
    "val_recall=recall_score(y_val, y_pred_val, average=\"macro\")\n",
    "val_precision=precision_score(y_val,y_pred_val,average=\"macro\")\n",
    "val_f1=f1_score(y_val,y_pred_val,average=\"macro\")\n",
    "\n",
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_precision))\n",
    "print(\"Recall: \"+str(train_recall))\n",
    "print(\"F1: \"+str(train_f1))\n",
    "\n",
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_precision))\n",
    "print(\"Recall: \"+str(val_recall))\n",
    "print(\"F1: \"+str(val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.9335147655462391\n",
      "Recall: 0.9190258213619221\n",
      "F1: 0.9258884661779716\n",
      "For validation \n",
      "\n",
      "Precision: 0.5775846133343651\n",
      "Recall: 0.5696832608303946\n",
      "F1: 0.572331894101405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Using Random Forest Classifier\n",
    "rfc=RandomForestClassifier(n_estimators=3, bootstrap = True, max_features = 'sqrt')\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred_train=rfc.predict(x_train).reshape(-1,1)\n",
    "y_pred_val=rfc.predict(x_val).reshape(-1,1)\n",
    "\n",
    "train_recall=recall_score(y_train, y_pred_train, average=\"macro\")\n",
    "train_precision=precision_score(y_train,y_pred_train,average=\"macro\")\n",
    "train_f1=f1_score(y_train,y_pred_train,average=\"macro\")\n",
    "\n",
    "val_recall=recall_score(y_val, y_pred_val, average=\"macro\")\n",
    "val_precision=precision_score(y_val,y_pred_val,average=\"macro\")\n",
    "val_f1=f1_score(y_val,y_pred_val,average=\"macro\")\n",
    "\n",
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_precision))\n",
    "print(\"Recall: \"+str(train_recall))\n",
    "print(\"F1: \"+str(train_f1))\n",
    "\n",
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_precision))\n",
    "print(\"Recall: \"+str(val_recall))\n",
    "print(\"F1: \"+str(val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true,y_pred):\n",
    "   precisions = precision(y_true, y_pred)\n",
    "   recalls = recall(y_true, y_pred)\n",
    "   return 2*((precisions*recalls)/(precisions+recalls+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410,)\n"
     ]
    }
   ],
   "source": [
    "y_train=y_train.reshape((y_train.shape[0],))\n",
    "print(y_train.shape)\n",
    "class_weights_values= class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "y_train=y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "11410/11410 [==============================] - 0s 30us/step - loss: 482063.6875 - mean_squared_error: 0.5810 - acc: 0.2931 - f1: 0.0641 - precision: 0.6683 - recall: 0.0336\n",
      "Epoch 2/10\n",
      "11410/11410 [==============================] - 0s 4us/step - loss: 0.6835 - mean_squared_error: 0.2418 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 3/10\n",
      "11410/11410 [==============================] - 0s 4us/step - loss: 0.6721 - mean_squared_error: 0.2369 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 4/10\n",
      "11410/11410 [==============================] - 0s 4us/step - loss: 0.6626 - mean_squared_error: 0.2327 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 5/10\n",
      "11410/11410 [==============================] - 0s 4us/step - loss: 0.6544 - mean_squared_error: 0.2289 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 6/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6473 - mean_squared_error: 0.2257 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 7/10\n",
      "11410/11410 [==============================] - 0s 4us/step - loss: 0.6411 - mean_squared_error: 0.2228 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 8/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6356 - mean_squared_error: 0.2203 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 9/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6308 - mean_squared_error: 0.2181 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 10/10\n",
      "11410/11410 [==============================] - 0s 6us/step - loss: 0.6266 - mean_squared_error: 0.2162 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(175, input_dim=x_train.shape[1], activation='relu',activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.080, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['mse','acc',f1,precision,recall])\n",
    "train=model.fit(x_train, y_train,epochs=10, verbose=1,class_weight=class_weights_values,batch_size=x_train.shape[0])\n",
    "train_model=model.evaluate(x_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7191060473373541\n",
      "Recall: 1.0\n",
      "F1: 0.82643346677842\n",
      "Accuracy: 0.7191060473373541\n"
     ]
    }
   ],
   "source": [
    "#For training\n",
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[4]))\n",
    "print(\"Recall: \"+str(train_model[5]))\n",
    "print(\"F1: \"+str(train_model[3]))\n",
    "print(\"Accuracy: \"+str(train_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model.evaluate(x_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7430774623203645\n",
      "Recall: 1.0\n",
      "F1: 0.8451232763077141\n",
      "Accuracy: 0.7430774623203645\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[4]))\n",
    "print(\"Recall: \"+str(val_model[5]))\n",
    "print(\"F1: \"+str(val_model[3]))\n",
    "print(\"Accuracy: \"+str(val_model[2]))\n",
    "\n",
    "model1_prec=val_model[4]\n",
    "model2_recall=val_model[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410, 1, 51)\n"
     ]
    }
   ],
   "source": [
    "#using LSTM\n",
    "new_x_train=x_train\n",
    "new_x_train= new_x_train.reshape((new_x_train.shape[0],1,new_x_train.shape[1]))\n",
    "print(new_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2853, 1, 51)\n"
     ]
    }
   ],
   "source": [
    "new_x_val=x_val\n",
    "new_x_val= new_x_val.reshape((new_x_val.shape[0],1,new_x_val.shape[1]))\n",
    "print(new_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11410 samples, validate on 2853 samples\n",
      "Epoch 1/60\n",
      " - 2s - loss: 1.3939 - mean_squared_error: 0.3663 - acc: 0.3975 - f1: 0.3958 - precision: 0.7095 - recall: 0.2745 - val_loss: 0.9217 - val_mean_squared_error: 0.3237 - val_acc: 0.4791 - val_f1: 0.5900 - val_precision: 0.7108 - val_recall: 0.5042\n",
      "Epoch 2/60\n",
      " - 0s - loss: 1.1471 - mean_squared_error: 0.3231 - acc: 0.4938 - f1: 0.5842 - precision: 0.7136 - recall: 0.4945 - val_loss: 0.7095 - val_mean_squared_error: 0.2549 - val_acc: 0.6200 - val_f1: 0.7517 - val_precision: 0.7306 - val_recall: 0.7741\n",
      "Epoch 3/60\n",
      " - 0s - loss: 0.9488 - mean_squared_error: 0.2847 - acc: 0.5767 - f1: 0.6940 - precision: 0.7226 - recall: 0.6676 - val_loss: 0.6105 - val_mean_squared_error: 0.2093 - val_acc: 0.7392 - val_f1: 0.8499 - val_precision: 0.7424 - val_recall: 0.9939\n",
      "Epoch 4/60\n",
      " - 0s - loss: 0.8846 - mean_squared_error: 0.2679 - acc: 0.6215 - f1: 0.7464 - precision: 0.7202 - recall: 0.7745 - val_loss: 0.5853 - val_mean_squared_error: 0.1975 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 5/60\n",
      " - 0s - loss: 0.8222 - mean_squared_error: 0.2529 - acc: 0.6504 - f1: 0.7760 - precision: 0.7196 - recall: 0.8419 - val_loss: 0.5826 - val_mean_squared_error: 0.1959 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 6/60\n",
      " - 0s - loss: 0.7983 - mean_squared_error: 0.2482 - acc: 0.6552 - f1: 0.7817 - precision: 0.7175 - recall: 0.8586 - val_loss: 0.5818 - val_mean_squared_error: 0.1951 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 7/60\n",
      " - 0s - loss: 0.7905 - mean_squared_error: 0.2436 - acc: 0.6670 - f1: 0.7921 - precision: 0.7187 - recall: 0.8820 - val_loss: 0.5807 - val_mean_squared_error: 0.1943 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 8/60\n",
      " - 0s - loss: 0.7570 - mean_squared_error: 0.2372 - acc: 0.6770 - f1: 0.7997 - precision: 0.7218 - recall: 0.8963 - val_loss: 0.5778 - val_mean_squared_error: 0.1935 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 9/60\n",
      " - 0s - loss: 0.7592 - mean_squared_error: 0.2390 - acc: 0.6768 - f1: 0.7996 - precision: 0.7215 - recall: 0.8966 - val_loss: 0.5772 - val_mean_squared_error: 0.1928 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 10/60\n",
      " - 0s - loss: 0.7372 - mean_squared_error: 0.2337 - acc: 0.6814 - f1: 0.8041 - precision: 0.7209 - recall: 0.9090 - val_loss: 0.5750 - val_mean_squared_error: 0.1922 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 11/60\n",
      " - 0s - loss: 0.7327 - mean_squared_error: 0.2340 - acc: 0.6788 - f1: 0.8027 - precision: 0.7189 - recall: 0.9085 - val_loss: 0.5728 - val_mean_squared_error: 0.1914 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 12/60\n",
      " - 0s - loss: 0.7063 - mean_squared_error: 0.2282 - acc: 0.6885 - f1: 0.8092 - precision: 0.7231 - recall: 0.9186 - val_loss: 0.5713 - val_mean_squared_error: 0.1908 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 13/60\n",
      " - 0s - loss: 0.7035 - mean_squared_error: 0.2273 - acc: 0.6878 - f1: 0.8099 - precision: 0.7204 - recall: 0.9247 - val_loss: 0.5698 - val_mean_squared_error: 0.1904 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 14/60\n",
      " - 0s - loss: 0.6974 - mean_squared_error: 0.2272 - acc: 0.6876 - f1: 0.8098 - precision: 0.7202 - recall: 0.9248 - val_loss: 0.5682 - val_mean_squared_error: 0.1899 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 15/60\n",
      " - 0s - loss: 0.6824 - mean_squared_error: 0.2240 - acc: 0.6892 - f1: 0.8106 - precision: 0.7214 - recall: 0.9250 - val_loss: 0.5668 - val_mean_squared_error: 0.1893 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 16/60\n",
      " - 0s - loss: 0.6847 - mean_squared_error: 0.2242 - acc: 0.6885 - f1: 0.8108 - precision: 0.7199 - recall: 0.9280 - val_loss: 0.5653 - val_mean_squared_error: 0.1887 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 17/60\n",
      " - 0s - loss: 0.6630 - mean_squared_error: 0.2196 - acc: 0.6943 - f1: 0.8151 - precision: 0.7213 - recall: 0.9370 - val_loss: 0.5643 - val_mean_squared_error: 0.1883 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 18/60\n",
      " - 0s - loss: 0.6675 - mean_squared_error: 0.2215 - acc: 0.6897 - f1: 0.8122 - precision: 0.7191 - recall: 0.9331 - val_loss: 0.5631 - val_mean_squared_error: 0.1880 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 19/60\n",
      " - 0s - loss: 0.6574 - mean_squared_error: 0.2179 - acc: 0.6954 - f1: 0.8159 - precision: 0.7216 - recall: 0.9386 - val_loss: 0.5622 - val_mean_squared_error: 0.1878 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 20/60\n",
      " - 0s - loss: 0.6476 - mean_squared_error: 0.2165 - acc: 0.6966 - f1: 0.8172 - precision: 0.7209 - recall: 0.9432 - val_loss: 0.5618 - val_mean_squared_error: 0.1876 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 21/60\n",
      " - 0s - loss: 0.6427 - mean_squared_error: 0.2164 - acc: 0.6932 - f1: 0.8147 - precision: 0.7201 - recall: 0.9380 - val_loss: 0.5605 - val_mean_squared_error: 0.1870 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 22/60\n",
      " - 0s - loss: 0.6421 - mean_squared_error: 0.2147 - acc: 0.6978 - f1: 0.8180 - precision: 0.7214 - recall: 0.9444 - val_loss: 0.5596 - val_mean_squared_error: 0.1867 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 23/60\n",
      " - 0s - loss: 0.6360 - mean_squared_error: 0.2132 - acc: 0.7022 - f1: 0.8209 - precision: 0.7233 - recall: 0.9489 - val_loss: 0.5588 - val_mean_squared_error: 0.1865 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 24/60\n",
      " - 0s - loss: 0.6304 - mean_squared_error: 0.2116 - acc: 0.7036 - f1: 0.8220 - precision: 0.7233 - recall: 0.9520 - val_loss: 0.5583 - val_mean_squared_error: 0.1863 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 25/60\n",
      " - 0s - loss: 0.6277 - mean_squared_error: 0.2110 - acc: 0.7035 - f1: 0.8222 - precision: 0.7229 - recall: 0.9531 - val_loss: 0.5573 - val_mean_squared_error: 0.1859 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 26/60\n",
      " - 0s - loss: 0.6260 - mean_squared_error: 0.2099 - acc: 0.7034 - f1: 0.8222 - precision: 0.7226 - recall: 0.9537 - val_loss: 0.5567 - val_mean_squared_error: 0.1856 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 27/60\n",
      " - 0s - loss: 0.6286 - mean_squared_error: 0.2115 - acc: 0.7026 - f1: 0.8216 - precision: 0.7225 - recall: 0.9521 - val_loss: 0.5568 - val_mean_squared_error: 0.1857 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 28/60\n",
      " - 0s - loss: 0.6202 - mean_squared_error: 0.2095 - acc: 0.7039 - f1: 0.8220 - precision: 0.7241 - recall: 0.9504 - val_loss: 0.5560 - val_mean_squared_error: 0.1853 - val_acc: 0.7427 - val_f1: 0.8524 - val_precision: 0.7430 - val_recall: 0.9995\n",
      "Epoch 29/60\n",
      " - 0s - loss: 0.6193 - mean_squared_error: 0.2084 - acc: 0.7041 - f1: 0.8227 - precision: 0.7229 - recall: 0.9544 - val_loss: 0.5563 - val_mean_squared_error: 0.1855 - val_acc: 0.7431 - val_f1: 0.8525 - val_precision: 0.7432 - val_recall: 0.9995\n",
      "Epoch 30/60\n",
      " - 0s - loss: 0.6199 - mean_squared_error: 0.2093 - acc: 0.6993 - f1: 0.8193 - precision: 0.7213 - recall: 0.9482 - val_loss: 0.5545 - val_mean_squared_error: 0.1847 - val_acc: 0.7427 - val_f1: 0.8523 - val_precision: 0.7432 - val_recall: 0.9991\n",
      "Epoch 31/60\n",
      " - 0s - loss: 0.6124 - mean_squared_error: 0.2063 - acc: 0.7096 - f1: 0.8266 - precision: 0.7243 - recall: 0.9625 - val_loss: 0.5558 - val_mean_squared_error: 0.1853 - val_acc: 0.7431 - val_f1: 0.8525 - val_precision: 0.7434 - val_recall: 0.9991\n",
      "Epoch 32/60\n",
      " - 0s - loss: 0.6094 - mean_squared_error: 0.2051 - acc: 0.7072 - f1: 0.8241 - precision: 0.7254 - recall: 0.9539 - val_loss: 0.5545 - val_mean_squared_error: 0.1848 - val_acc: 0.7431 - val_f1: 0.8524 - val_precision: 0.7438 - val_recall: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      " - 0s - loss: 0.6094 - mean_squared_error: 0.2057 - acc: 0.7055 - f1: 0.8235 - precision: 0.7236 - recall: 0.9555 - val_loss: 0.5545 - val_mean_squared_error: 0.1847 - val_acc: 0.7434 - val_f1: 0.8527 - val_precision: 0.7437 - val_recall: 0.9991\n",
      "Epoch 34/60\n",
      " - 0s - loss: 0.6072 - mean_squared_error: 0.2051 - acc: 0.7089 - f1: 0.8255 - precision: 0.7254 - recall: 0.9576 - val_loss: 0.5539 - val_mean_squared_error: 0.1845 - val_acc: 0.7424 - val_f1: 0.8520 - val_precision: 0.7434 - val_recall: 0.9976\n",
      "Epoch 35/60\n",
      " - 0s - loss: 0.6100 - mean_squared_error: 0.2051 - acc: 0.7080 - f1: 0.8251 - precision: 0.7247 - recall: 0.9578 - val_loss: 0.5525 - val_mean_squared_error: 0.1840 - val_acc: 0.7427 - val_f1: 0.8521 - val_precision: 0.7437 - val_recall: 0.9976\n",
      "Epoch 36/60\n",
      " - 0s - loss: 0.6049 - mean_squared_error: 0.2039 - acc: 0.7093 - f1: 0.8266 - precision: 0.7238 - recall: 0.9634 - val_loss: 0.5533 - val_mean_squared_error: 0.1843 - val_acc: 0.7441 - val_f1: 0.8528 - val_precision: 0.7447 - val_recall: 0.9976\n",
      "Epoch 37/60\n",
      " - 0s - loss: 0.6009 - mean_squared_error: 0.2021 - acc: 0.7089 - f1: 0.8264 - precision: 0.7234 - recall: 0.9636 - val_loss: 0.5529 - val_mean_squared_error: 0.1841 - val_acc: 0.7438 - val_f1: 0.8527 - val_precision: 0.7445 - val_recall: 0.9976\n",
      "Epoch 38/60\n",
      " - 0s - loss: 0.6041 - mean_squared_error: 0.2039 - acc: 0.7064 - f1: 0.8245 - precision: 0.7231 - recall: 0.9589 - val_loss: 0.5517 - val_mean_squared_error: 0.1836 - val_acc: 0.7448 - val_f1: 0.8532 - val_precision: 0.7452 - val_recall: 0.9976\n",
      "Epoch 39/60\n",
      " - 0s - loss: 0.5976 - mean_squared_error: 0.2016 - acc: 0.7131 - f1: 0.8294 - precision: 0.7247 - recall: 0.9694 - val_loss: 0.5537 - val_mean_squared_error: 0.1845 - val_acc: 0.7434 - val_f1: 0.8522 - val_precision: 0.7451 - val_recall: 0.9953\n",
      "Epoch 40/60\n",
      " - 0s - loss: 0.6041 - mean_squared_error: 0.2033 - acc: 0.7083 - f1: 0.8252 - precision: 0.7252 - recall: 0.9571 - val_loss: 0.5528 - val_mean_squared_error: 0.1841 - val_acc: 0.7427 - val_f1: 0.8516 - val_precision: 0.7452 - val_recall: 0.9934\n",
      "Epoch 41/60\n",
      " - 0s - loss: 0.5986 - mean_squared_error: 0.2022 - acc: 0.7082 - f1: 0.8248 - precision: 0.7257 - recall: 0.9551 - val_loss: 0.5516 - val_mean_squared_error: 0.1837 - val_acc: 0.7427 - val_f1: 0.8517 - val_precision: 0.7450 - val_recall: 0.9939\n",
      "Epoch 42/60\n",
      " - 0s - loss: 0.5994 - mean_squared_error: 0.2019 - acc: 0.7123 - f1: 0.8284 - precision: 0.7252 - recall: 0.9658 - val_loss: 0.5516 - val_mean_squared_error: 0.1836 - val_acc: 0.7438 - val_f1: 0.8522 - val_precision: 0.7457 - val_recall: 0.9943\n",
      "Epoch 43/60\n",
      " - 0s - loss: 0.5988 - mean_squared_error: 0.2020 - acc: 0.7112 - f1: 0.8273 - precision: 0.7259 - recall: 0.9616 - val_loss: 0.5520 - val_mean_squared_error: 0.1838 - val_acc: 0.7434 - val_f1: 0.8521 - val_precision: 0.7454 - val_recall: 0.9943\n",
      "Epoch 44/60\n",
      " - 0s - loss: 0.6003 - mean_squared_error: 0.2026 - acc: 0.7102 - f1: 0.8269 - precision: 0.7248 - recall: 0.9625 - val_loss: 0.5523 - val_mean_squared_error: 0.1839 - val_acc: 0.7431 - val_f1: 0.8518 - val_precision: 0.7455 - val_recall: 0.9934\n",
      "Epoch 45/60\n",
      " - 0s - loss: 0.5997 - mean_squared_error: 0.2021 - acc: 0.7109 - f1: 0.8269 - precision: 0.7261 - recall: 0.9600 - val_loss: 0.5517 - val_mean_squared_error: 0.1837 - val_acc: 0.7434 - val_f1: 0.8521 - val_precision: 0.7454 - val_recall: 0.9943\n",
      "Epoch 46/60\n",
      " - 0s - loss: 0.5939 - mean_squared_error: 0.2008 - acc: 0.7109 - f1: 0.8278 - precision: 0.7239 - recall: 0.9665 - val_loss: 0.5498 - val_mean_squared_error: 0.1829 - val_acc: 0.7434 - val_f1: 0.8520 - val_precision: 0.7456 - val_recall: 0.9939\n",
      "Epoch 47/60\n",
      " - 0s - loss: 0.5942 - mean_squared_error: 0.2010 - acc: 0.7092 - f1: 0.8265 - precision: 0.7237 - recall: 0.9633 - val_loss: 0.5502 - val_mean_squared_error: 0.1831 - val_acc: 0.7441 - val_f1: 0.8522 - val_precision: 0.7466 - val_recall: 0.9925\n",
      "Epoch 48/60\n",
      " - 0s - loss: 0.5904 - mean_squared_error: 0.1991 - acc: 0.7130 - f1: 0.8286 - precision: 0.7261 - recall: 0.9647 - val_loss: 0.5507 - val_mean_squared_error: 0.1833 - val_acc: 0.7438 - val_f1: 0.8519 - val_precision: 0.7467 - val_recall: 0.9915\n",
      "Epoch 49/60\n",
      " - 0s - loss: 0.5885 - mean_squared_error: 0.1988 - acc: 0.7137 - f1: 0.8286 - precision: 0.7273 - recall: 0.9627 - val_loss: 0.5479 - val_mean_squared_error: 0.1821 - val_acc: 0.7445 - val_f1: 0.8528 - val_precision: 0.7457 - val_recall: 0.9958\n",
      "Epoch 50/60\n",
      " - 0s - loss: 0.5936 - mean_squared_error: 0.1995 - acc: 0.7141 - f1: 0.8302 - precision: 0.7247 - recall: 0.9716 - val_loss: 0.5507 - val_mean_squared_error: 0.1833 - val_acc: 0.7448 - val_f1: 0.8526 - val_precision: 0.7468 - val_recall: 0.9934\n",
      "Epoch 51/60\n",
      " - 0s - loss: 0.5875 - mean_squared_error: 0.1982 - acc: 0.7166 - f1: 0.8309 - precision: 0.7277 - recall: 0.9682 - val_loss: 0.5503 - val_mean_squared_error: 0.1832 - val_acc: 0.7431 - val_f1: 0.8513 - val_precision: 0.7469 - val_recall: 0.9896\n",
      "Epoch 52/60\n",
      " - 0s - loss: 0.5813 - mean_squared_error: 0.1960 - acc: 0.7167 - f1: 0.8308 - precision: 0.7280 - recall: 0.9673 - val_loss: 0.5485 - val_mean_squared_error: 0.1824 - val_acc: 0.7427 - val_f1: 0.8514 - val_precision: 0.7457 - val_recall: 0.9920\n",
      "Epoch 53/60\n",
      " - 0s - loss: 0.5898 - mean_squared_error: 0.1985 - acc: 0.7133 - f1: 0.8291 - precision: 0.7257 - recall: 0.9667 - val_loss: 0.5496 - val_mean_squared_error: 0.1829 - val_acc: 0.7448 - val_f1: 0.8525 - val_precision: 0.7473 - val_recall: 0.9920\n",
      "Epoch 54/60\n",
      " - 0s - loss: 0.5861 - mean_squared_error: 0.1981 - acc: 0.7157 - f1: 0.8304 - precision: 0.7271 - recall: 0.9678 - val_loss: 0.5480 - val_mean_squared_error: 0.1822 - val_acc: 0.7438 - val_f1: 0.8521 - val_precision: 0.7462 - val_recall: 0.9929\n",
      "Epoch 55/60\n",
      " - 0s - loss: 0.5835 - mean_squared_error: 0.1968 - acc: 0.7163 - f1: 0.8310 - precision: 0.7268 - recall: 0.9701 - val_loss: 0.5493 - val_mean_squared_error: 0.1828 - val_acc: 0.7452 - val_f1: 0.8527 - val_precision: 0.7474 - val_recall: 0.9925\n",
      "Epoch 56/60\n",
      " - 0s - loss: 0.5863 - mean_squared_error: 0.1978 - acc: 0.7160 - f1: 0.8304 - precision: 0.7277 - recall: 0.9667 - val_loss: 0.5496 - val_mean_squared_error: 0.1828 - val_acc: 0.7445 - val_f1: 0.8522 - val_precision: 0.7472 - val_recall: 0.9915\n",
      "Epoch 57/60\n",
      " - 0s - loss: 0.5850 - mean_squared_error: 0.1973 - acc: 0.7169 - f1: 0.8315 - precision: 0.7270 - recall: 0.9710 - val_loss: 0.5487 - val_mean_squared_error: 0.1825 - val_acc: 0.7452 - val_f1: 0.8527 - val_precision: 0.7474 - val_recall: 0.9925\n",
      "Epoch 58/60\n",
      " - 0s - loss: 0.5820 - mean_squared_error: 0.1967 - acc: 0.7176 - f1: 0.8319 - precision: 0.7273 - recall: 0.9715 - val_loss: 0.5493 - val_mean_squared_error: 0.1827 - val_acc: 0.7445 - val_f1: 0.8522 - val_precision: 0.7472 - val_recall: 0.9915\n",
      "Epoch 59/60\n",
      " - 0s - loss: 0.5820 - mean_squared_error: 0.1963 - acc: 0.7177 - f1: 0.8321 - precision: 0.7271 - recall: 0.9725 - val_loss: 0.5477 - val_mean_squared_error: 0.1822 - val_acc: 0.7438 - val_f1: 0.8518 - val_precision: 0.7471 - val_recall: 0.9906\n",
      "Epoch 60/60\n",
      " - 0s - loss: 0.5830 - mean_squared_error: 0.1962 - acc: 0.7167 - f1: 0.8314 - precision: 0.7266 - recall: 0.9716 - val_loss: 0.5490 - val_mean_squared_error: 0.1827 - val_acc: 0.7441 - val_f1: 0.8517 - val_precision: 0.7479 - val_recall: 0.9892\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(175,input_shape=(1,x.shape[1]),return_sequences=True,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#es=EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=2, mode='auto')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['mse','acc',f1,precision,recall])\n",
    "train=model.fit(new_x_train, y_train,epochs=60, verbose=2,class_weight=class_weights_values,batch_size=x_train.shape[0],validation_data=(new_x_val, y_val))\n",
    "train_model=model.evaluate(new_x_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7242916825254375\n",
      "Recall: 0.9907047804983743\n",
      "F1: 0.8270446840866317\n",
      "Accuracy: 0.7234005258649614\n"
     ]
    }
   ],
   "source": [
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[4]))\n",
    "print(\"Recall: \"+str(train_model[5]))\n",
    "print(\"F1: \"+str(train_model[3]))\n",
    "print(\"Accuracy: \"+str(train_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model.evaluate(new_x_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7481575139229899\n",
      "Recall: 0.989601422726711\n",
      "F1: 0.8444051558704824\n",
      "Accuracy: 0.7441289870311952\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[4]))\n",
    "print(\"Recall: \"+str(val_model[5]))\n",
    "print(\"F1: \"+str(val_model[3]))\n",
    "print(\"Accuracy: \"+str(val_model[2]))\n",
    "\n",
    "model2_prec=val_model[4]\n",
    "model2_recall=val_model[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 1200\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(data_train['sentences'])\n",
    "sequences = tokenizer.texts_to_sequences(data_train['sentences'])\n",
    "data_words_train = pad_sequences(sequences, maxlen=50)\n",
    "#data_words_train=np.append(data_words_train, tagm,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 3s - loss: 0.6863 - mean_squared_error: 0.2466 - acc: 0.5735 - f1: 0.6872 - precision: 0.7271 - recall: 0.6514\n",
      "Epoch 2/30\n",
      " - 1s - loss: 0.7852 - mean_squared_error: 0.2345 - acc: 0.7200 - f1: 0.8369 - precision: 0.7200 - recall: 0.9990\n",
      "Epoch 3/30\n",
      " - 1s - loss: 0.6080 - mean_squared_error: 0.2084 - acc: 0.7243 - f1: 0.8380 - precision: 0.7255 - recall: 0.9918\n",
      "Epoch 4/30\n",
      " - 1s - loss: 0.5732 - mean_squared_error: 0.1933 - acc: 0.7232 - f1: 0.8376 - precision: 0.7244 - recall: 0.9928\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.5705 - mean_squared_error: 0.1922 - acc: 0.7247 - f1: 0.8382 - precision: 0.7259 - recall: 0.9917\n",
      "Epoch 6/30\n",
      " - 1s - loss: 0.5664 - mean_squared_error: 0.1907 - acc: 0.7258 - f1: 0.8387 - precision: 0.7267 - recall: 0.9916\n",
      "Epoch 7/30\n",
      " - 1s - loss: 0.5647 - mean_squared_error: 0.1899 - acc: 0.7266 - f1: 0.8390 - precision: 0.7276 - recall: 0.9907\n",
      "Epoch 8/30\n",
      " - 1s - loss: 0.5610 - mean_squared_error: 0.1886 - acc: 0.7272 - f1: 0.8393 - precision: 0.7279 - recall: 0.9911\n",
      "Epoch 9/30\n",
      " - 1s - loss: 0.5574 - mean_squared_error: 0.1870 - acc: 0.7280 - f1: 0.8397 - precision: 0.7288 - recall: 0.9904\n",
      "Epoch 10/30\n",
      " - 1s - loss: 0.5539 - mean_squared_error: 0.1857 - acc: 0.7288 - f1: 0.8401 - precision: 0.7294 - recall: 0.9902\n",
      "Epoch 11/30\n",
      " - 1s - loss: 0.5501 - mean_squared_error: 0.1842 - acc: 0.7305 - f1: 0.8409 - precision: 0.7306 - recall: 0.9904\n",
      "Epoch 12/30\n",
      " - 1s - loss: 0.5463 - mean_squared_error: 0.1827 - acc: 0.7303 - f1: 0.8407 - precision: 0.7307 - recall: 0.9899\n",
      "Epoch 13/30\n",
      " - 1s - loss: 0.5403 - mean_squared_error: 0.1805 - acc: 0.7308 - f1: 0.8408 - precision: 0.7315 - recall: 0.9884\n",
      "Epoch 14/30\n",
      " - 1s - loss: 0.5352 - mean_squared_error: 0.1785 - acc: 0.7316 - f1: 0.8412 - precision: 0.7321 - recall: 0.9885\n",
      "Epoch 15/30\n",
      " - 1s - loss: 0.5300 - mean_squared_error: 0.1766 - acc: 0.7323 - f1: 0.8414 - precision: 0.7329 - recall: 0.9876\n",
      "Epoch 16/30\n",
      " - 1s - loss: 0.5270 - mean_squared_error: 0.1751 - acc: 0.7344 - f1: 0.8420 - precision: 0.7356 - recall: 0.9844\n",
      "Epoch 17/30\n",
      " - 1s - loss: 0.5219 - mean_squared_error: 0.1738 - acc: 0.7340 - f1: 0.8422 - precision: 0.7345 - recall: 0.9868\n",
      "Epoch 18/30\n",
      " - 1s - loss: 0.5241 - mean_squared_error: 0.1730 - acc: 0.7457 - f1: 0.8470 - precision: 0.7467 - recall: 0.9784\n",
      "Epoch 19/30\n",
      " - 1s - loss: 0.5518 - mean_squared_error: 0.1843 - acc: 0.7337 - f1: 0.8425 - precision: 0.7332 - recall: 0.9900\n",
      "Epoch 20/30\n",
      " - 1s - loss: 0.5675 - mean_squared_error: 0.1910 - acc: 0.7656 - f1: 0.8468 - precision: 0.7987 - recall: 0.9012\n",
      "Epoch 21/30\n",
      " - 1s - loss: 0.5159 - mean_squared_error: 0.1722 - acc: 0.7396 - f1: 0.8448 - precision: 0.7392 - recall: 0.9857\n",
      "Epoch 22/30\n",
      " - 1s - loss: 0.5061 - mean_squared_error: 0.1659 - acc: 0.7621 - f1: 0.8530 - precision: 0.7677 - recall: 0.9597\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.4970 - mean_squared_error: 0.1651 - acc: 0.7472 - f1: 0.8479 - precision: 0.7473 - recall: 0.9798\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.4910 - mean_squared_error: 0.1603 - acc: 0.7672 - f1: 0.8536 - precision: 0.7790 - recall: 0.9441\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.4855 - mean_squared_error: 0.1606 - acc: 0.7556 - f1: 0.8518 - precision: 0.7550 - recall: 0.9771\n",
      "Epoch 26/30\n",
      " - 1s - loss: 0.4822 - mean_squared_error: 0.1566 - acc: 0.7791 - f1: 0.8572 - precision: 0.8009 - recall: 0.9220\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.4804 - mean_squared_error: 0.1594 - acc: 0.7574 - f1: 0.8535 - precision: 0.7545 - recall: 0.9823\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.4788 - mean_squared_error: 0.1549 - acc: 0.7872 - f1: 0.8585 - precision: 0.8226 - recall: 0.8976\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.4773 - mean_squared_error: 0.1588 - acc: 0.7605 - f1: 0.8555 - precision: 0.7554 - recall: 0.9862\n",
      "Epoch 30/30\n",
      " - 1s - loss: 0.4694 - mean_squared_error: 0.1513 - acc: 0.7923 - f1: 0.8617 - precision: 0.8266 - recall: 0.8999\n"
     ]
    }
   ],
   "source": [
    "#using LSTM for word embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(1200, 100, input_length=50))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#es=EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=2, mode='auto')\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['mse','acc',f1,precision,recall])\n",
    "train=model.fit(data_words_train, y_train,epochs=30, verbose=2,class_weight=class_weights_values,batch_size=x_train.shape[0])\n",
    "train_model=model.evaluate(data_words_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7594832291632342\n",
      "Recall: 0.9853250294584229\n",
      "F1: 0.8501454054734667\n",
      "Accuracy: 0.7707274320353341\n"
     ]
    }
   ],
   "source": [
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[4]))\n",
    "print(\"Recall: \"+str(train_model[5]))\n",
    "print(\"F1: \"+str(train_model[3]))\n",
    "print(\"Accuracy: \"+str(train_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 1200\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(data_val['sentences'])\n",
    "sequences = tokenizer.texts_to_sequences(data_val['sentences'])\n",
    "data_words_val = pad_sequences(sequences, maxlen=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model.evaluate(data_words_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7501297164205664\n",
      "Recall: 0.9583619482426153\n",
      "F1: 0.8333367870182394\n",
      "Accuracy: 0.7308096740273397\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[4]))\n",
    "print(\"Recall: \"+str(val_model[5]))\n",
    "print(\"F1: \"+str(val_model[3]))\n",
    "print(\"Accuracy: \"+str(val_model[2]))\n",
    "model1_prec=val_model[4]\n",
    "model2_recall=val_model[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "11410/11410 [==============================] - 12s 1ms/step - loss: 0.5684 - acc: 0.7223 - f1: 0.8325 - precision: 0.7298 - recall: 0.9769\n",
      "Epoch 2/3\n",
      "11410/11410 [==============================] - 11s 944us/step - loss: 0.5296 - acc: 0.7490 - f1: 0.8408 - precision: 0.7645 - recall: 0.9426\n",
      "Epoch 3/3\n",
      "11410/11410 [==============================] - 11s 931us/step - loss: 0.5055 - acc: 0.7656 - f1: 0.8500 - precision: 0.7788 - recall: 0.9435\n"
     ]
    }
   ],
   "source": [
    "#Using CNN for word embeddings\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Conv1D(175, 5, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(175,activation='relu'))\n",
    "model_conv.add(Dense(1, activation='sigmoid'))\n",
    "model_conv.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy',f1,precision,recall])\n",
    "train=model_conv.fit(data_words_train, y_train, epochs=3,class_weight=class_weights_values)\n",
    "train_model=model_conv.evaluate(data_words_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7596727901127754\n",
      "Recall: 0.9714273364161525\n",
      "F1: 0.8459418138634417\n",
      "Accuracy: 0.7670464504402421\n"
     ]
    }
   ],
   "source": [
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[3]))\n",
    "print(\"Recall: \"+str(train_model[4]))\n",
    "print(\"F1: \"+str(train_model[2]))\n",
    "print(\"Accuracy: \"+str(train_model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model_conv.evaluate(data_words_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7497233782907641\n",
      "Recall: 0.9513095911870368\n",
      "F1: 0.830600403586146\n",
      "Accuracy: 0.727304591657904\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[3]))\n",
    "print(\"Recall: \"+str(val_model[4]))\n",
    "print(\"F1: \"+str(val_model[2]))\n",
    "print(\"Accuracy: \"+str(val_model[1]))\n",
    "model1_prec=val_model[3]\n",
    "model2_recall=val_model[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
