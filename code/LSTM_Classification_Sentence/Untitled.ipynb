{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout,Conv1D,MaxPooling1D,initializers,Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers,regularizers\n",
    "from keras.callbacks import History,EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from collections import namedtuple\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.models import doc2vec\n",
    "from gensim import models\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentences', 'article', 'N_sentence', 'is_propaganda', 'sadness', 'joy', 'fear', 'disgust', 'anger']\n"
     ]
    }
   ],
   "source": [
    "print(list(data.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(x):\n",
    " x=x.lower()\n",
    " tokenizer = RegexpTokenizer(r'\\w+')\n",
    " x=(tokenizer.tokenize(x))\n",
    " filtered_words =([word for word in x if word not in stopwords.words('english')])\n",
    " filtered_words=\" \".join(filtered_words)\n",
    " st = PorterStemmer()\n",
    " stemmed_words = ' '.join(([st.stem(word) for word in filtered_words]))\n",
    " return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"new_sentences\"] = data[\"sentences\"].apply(lambda x: tokenise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_values=[]\n",
    "docs=[]\n",
    "y= np.array([])\n",
    "for index, row in data.iterrows():\n",
    " w=row[\"new_sentences\"].split()\n",
    " word_value=row[\"new_sentences\"].split()\n",
    " t1=[i]\n",
    " all_tags=nltk.pos_tag(row[\"sentences\"].split())\n",
    " tag_values.append(all_tags)\n",
    " #t=[row[\"sadness\"],row[\"joy\"],row[\"fear\"],row[\"disgust\"],row[\"anger\"]]\n",
    " #val=[i[1] for i in t1]\n",
    " docs.append(TaggedDocument(words=w, tags=t1))\n",
    " if(row[\"is_propaganda\"]==\"propaganda\"):\n",
    "        y=np.append(y, 0)\n",
    " else:\n",
    "    y=np.append(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14263, 35)\n"
     ]
    }
   ],
   "source": [
    "#including grammatical features nouns, pronouns, etc\n",
    "pos_tags=['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP','TO','UH','VB','VBD','VBG','VBN','VBP','VBZ','WDT','WP','WP$','WRB']\n",
    "tagm = [[sum(sen,()).count(tag) for tag in pos_tags] for sen in tag_values]\n",
    "tagm=np.array(tagm)\n",
    "print(tagm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=10\n",
    "model = models.Doc2Vec(vector_size=size, window=3, min_count=2, workers=4, epochs=20)\n",
    "model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.train(docs, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"tag '293' not seen in training corpus/invalid\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-2691b1b38a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minteger_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tag '%s' not seen in training corpus/invalid\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"tag '293' not seen in training corpus/invalid\""
     ]
    }
   ],
   "source": [
    "y=y.reshape(-1, 1)\n",
    "x=np.zeros((y.shape[0], size))\n",
    "for i in range(y.shape[0]):\n",
    "    x[i]=model[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27609899740587535\n",
      "0.7239010025941247\n"
     ]
    }
   ],
   "source": [
    "count_0=np.sum(y==0)\n",
    "count_1=np.sum(y==1)\n",
    "\n",
    "print(count_0/y.shape[0])\n",
    "print(count_1/y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14263, 51)\n"
     ]
    }
   ],
   "source": [
    "values=np.array(data.iloc[:,4:9])\n",
    "values2=np.array(data.iloc[:,2:3])\n",
    "x=np.append(x, values, axis=1)\n",
    "x=np.append(x, values2,axis=1)\n",
    "x=np.append(x, tagm,axis=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410, 51)\n",
      "(2853, 51)\n"
     ]
    }
   ],
   "source": [
    "split_index=int(y.shape[0]*0.8)\n",
    "y_train=y[0:split_index, :]\n",
    "x_train=x[0:split_index,:]\n",
    "y_val=y[split_index:,:]\n",
    "x_val=x[split_index:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "\n",
    "data_train= data.iloc[0:split_index,0:1]\n",
    "data_val=data.iloc[split_index:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28089395267309375\n",
      "0.7191060473269062\n"
     ]
    }
   ],
   "source": [
    "count_0_train=np.sum(y_train==0)\n",
    "count_1_train=np.sum(y_train==1)\n",
    "\n",
    "print(count_0_train/y_train.shape[0])\n",
    "print(count_1_train/y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25692253767963547\n",
      "0.7430774623203645\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "count_0=np.sum(y_val==0)\n",
    "count_1=np.sum(y_val==1)\n",
    "\n",
    "print(count_0/y_val.shape[0])\n",
    "print(count_1/y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PCA\n",
      "0.7293602103418054\n",
      "0.745881528215913\n",
      "Without PCA\n",
      "0.7382997370727432\n",
      "0.7511391517700666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Using Logistic Regression as baseline\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(x_train)\n",
    "new_x_train=pca.transform(x_train)\n",
    "new_x_val=pca.transform(x_val)\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(new_x_train, y_train)\n",
    "print(\"With PCA\")\n",
    "print(logReg.score(new_x_train, y_train)) #Accuracy on train\n",
    "\n",
    "#on val\n",
    "print(logReg.score(new_x_val,y_val))\n",
    "print(\"Without PCA\")\n",
    "logReg.fit(x_train, y_train)\n",
    "print(logReg.score(x_train, y_train))\n",
    "print(logReg.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C = 1.0)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146434294871795\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(x_train,y_train)) #Training score\n",
    "print(clf.score(x_val,y_val)) #validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true,y_pred):\n",
    "   precisions = precision(y_true, y_pred)\n",
    "   recalls = recall(y_true, y_pred)\n",
    "   return 2*((precisions*recalls)/(precisions+recalls+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410,)\n"
     ]
    }
   ],
   "source": [
    "y_train=y_train.reshape((y_train.shape[0],))\n",
    "print(y_train.shape)\n",
    "class_weights_values= class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
    "y_train=y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 2s - loss: 10.1051 - mean_squared_error: 0.6275 - acc: 0.3725 - f1: 0.3159\n",
      "Epoch 2/500\n",
      " - 0s - loss: 10.3123 - mean_squared_error: 0.6404 - acc: 0.3596 - f1: 0.2920\n",
      "Epoch 3/500\n",
      " - 0s - loss: 10.2225 - mean_squared_error: 0.6348 - acc: 0.3652 - f1: 0.3048\n",
      "Epoch 4/500\n",
      " - 0s - loss: 10.0756 - mean_squared_error: 0.6257 - acc: 0.3743 - f1: 0.3163\n",
      "Epoch 5/500\n",
      " - 0s - loss: 10.3188 - mean_squared_error: 0.6409 - acc: 0.3591 - f1: 0.3029\n",
      "Epoch 6/500\n",
      " - 0s - loss: 10.2554 - mean_squared_error: 0.6369 - acc: 0.3631 - f1: 0.3016\n",
      "Epoch 7/500\n",
      " - 0s - loss: 10.1907 - mean_squared_error: 0.6329 - acc: 0.3671 - f1: 0.3125\n",
      "Epoch 8/500\n",
      " - 0s - loss: 10.2240 - mean_squared_error: 0.6349 - acc: 0.3651 - f1: 0.3052\n",
      "Epoch 9/500\n",
      " - 0s - loss: 10.2740 - mean_squared_error: 0.6380 - acc: 0.3620 - f1: 0.3019\n",
      "Epoch 10/500\n",
      " - 0s - loss: 10.0645 - mean_squared_error: 0.6250 - acc: 0.3750 - f1: 0.3185\n",
      "Epoch 11/500\n",
      " - 0s - loss: 10.1536 - mean_squared_error: 0.6305 - acc: 0.3695 - f1: 0.3118\n",
      "Epoch 12/500\n",
      " - 0s - loss: 10.2396 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.3047\n",
      "Epoch 13/500\n",
      " - 0s - loss: 10.1329 - mean_squared_error: 0.6293 - acc: 0.3707 - f1: 0.3163\n",
      "Epoch 14/500\n",
      " - 0s - loss: 10.2401 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.2998\n",
      "Epoch 15/500\n",
      " - 0s - loss: 10.3091 - mean_squared_error: 0.6402 - acc: 0.3598 - f1: 0.2928\n",
      "Epoch 16/500\n",
      " - 0s - loss: 10.2882 - mean_squared_error: 0.6389 - acc: 0.3611 - f1: 0.2997\n",
      "Epoch 17/500\n",
      " - 0s - loss: 10.1035 - mean_squared_error: 0.6274 - acc: 0.3726 - f1: 0.3158\n",
      "Epoch 18/500\n",
      " - 0s - loss: 10.2203 - mean_squared_error: 0.6347 - acc: 0.3653 - f1: 0.3107\n",
      "Epoch 19/500\n",
      " - 0s - loss: 10.2568 - mean_squared_error: 0.6370 - acc: 0.3630 - f1: 0.3032\n",
      "Epoch 20/500\n",
      " - 0s - loss: 10.1720 - mean_squared_error: 0.6317 - acc: 0.3683 - f1: 0.3135\n",
      "Epoch 21/500\n",
      " - 0s - loss: 10.2349 - mean_squared_error: 0.6356 - acc: 0.3644 - f1: 0.3050\n",
      "Epoch 22/500\n",
      " - 0s - loss: 10.2101 - mean_squared_error: 0.6340 - acc: 0.3660 - f1: 0.3052\n",
      "Epoch 23/500\n",
      " - 0s - loss: 10.2082 - mean_squared_error: 0.6339 - acc: 0.3661 - f1: 0.3085\n",
      "Epoch 24/500\n",
      " - 0s - loss: 10.1991 - mean_squared_error: 0.6334 - acc: 0.3666 - f1: 0.3063\n",
      "Epoch 25/500\n",
      " - 0s - loss: 10.1864 - mean_squared_error: 0.6326 - acc: 0.3674 - f1: 0.3089\n",
      "Epoch 26/500\n",
      " - 0s - loss: 10.2590 - mean_squared_error: 0.6371 - acc: 0.3629 - f1: 0.2972\n",
      "Epoch 27/500\n",
      " - 0s - loss: 10.1228 - mean_squared_error: 0.6286 - acc: 0.3714 - f1: 0.3103\n",
      "Epoch 28/500\n",
      " - 0s - loss: 10.2036 - mean_squared_error: 0.6337 - acc: 0.3663 - f1: 0.3074\n",
      "Epoch 29/500\n",
      " - 0s - loss: 10.0676 - mean_squared_error: 0.6252 - acc: 0.3748 - f1: 0.3189\n",
      "Epoch 30/500\n",
      " - 0s - loss: 10.1336 - mean_squared_error: 0.6293 - acc: 0.3707 - f1: 0.3101\n",
      "Epoch 31/500\n",
      " - 0s - loss: 10.2653 - mean_squared_error: 0.6375 - acc: 0.3625 - f1: 0.2966\n",
      "Epoch 32/500\n",
      " - 0s - loss: 10.2588 - mean_squared_error: 0.6371 - acc: 0.3629 - f1: 0.2991\n",
      "Epoch 33/500\n",
      " - 0s - loss: 10.1790 - mean_squared_error: 0.6321 - acc: 0.3679 - f1: 0.3061\n",
      "Epoch 34/500\n",
      " - 0s - loss: 10.1834 - mean_squared_error: 0.6324 - acc: 0.3676 - f1: 0.3083\n",
      "Epoch 35/500\n",
      " - 0s - loss: 10.0782 - mean_squared_error: 0.6259 - acc: 0.3741 - f1: 0.3204\n",
      "Epoch 36/500\n",
      " - 0s - loss: 10.3106 - mean_squared_error: 0.6403 - acc: 0.3597 - f1: 0.2931\n",
      "Epoch 37/500\n",
      " - 0s - loss: 10.2791 - mean_squared_error: 0.6383 - acc: 0.3617 - f1: 0.2980\n",
      "Epoch 38/500\n",
      " - 0s - loss: 10.2475 - mean_squared_error: 0.6364 - acc: 0.3636 - f1: 0.3032\n",
      "Epoch 39/500\n",
      " - 0s - loss: 10.0538 - mean_squared_error: 0.6243 - acc: 0.3757 - f1: 0.3173\n",
      "Epoch 40/500\n",
      " - 0s - loss: 10.1975 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3066\n",
      "Epoch 41/500\n",
      " - 0s - loss: 10.1558 - mean_squared_error: 0.6306 - acc: 0.3694 - f1: 0.3060\n",
      "Epoch 42/500\n",
      " - 0s - loss: 10.3101 - mean_squared_error: 0.6403 - acc: 0.3597 - f1: 0.2979\n",
      "Epoch 43/500\n",
      " - 0s - loss: 10.1711 - mean_squared_error: 0.6316 - acc: 0.3684 - f1: 0.3073\n",
      "Epoch 44/500\n",
      " - 0s - loss: 10.3307 - mean_squared_error: 0.6415 - acc: 0.3585 - f1: 0.2931\n",
      "Epoch 45/500\n",
      " - 0s - loss: 10.2904 - mean_squared_error: 0.6390 - acc: 0.3610 - f1: 0.2940\n",
      "Epoch 46/500\n",
      " - 0s - loss: 10.2603 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.3000\n",
      "Epoch 47/500\n",
      " - 0s - loss: 10.2207 - mean_squared_error: 0.6347 - acc: 0.3653 - f1: 0.3072\n",
      "Epoch 48/500\n",
      " - 0s - loss: 10.1769 - mean_squared_error: 0.6320 - acc: 0.3680 - f1: 0.3112\n",
      "Epoch 49/500\n",
      " - 0s - loss: 10.2920 - mean_squared_error: 0.6391 - acc: 0.3609 - f1: 0.2930\n",
      "Epoch 50/500\n",
      " - 0s - loss: 10.1775 - mean_squared_error: 0.6320 - acc: 0.3680 - f1: 0.3060\n",
      "Epoch 51/500\n",
      " - 0s - loss: 10.1901 - mean_squared_error: 0.6328 - acc: 0.3672 - f1: 0.3040\n",
      "Epoch 52/500\n",
      " - 0s - loss: 10.2164 - mean_squared_error: 0.6344 - acc: 0.3656 - f1: 0.3042\n",
      "Epoch 53/500\n",
      " - 0s - loss: 10.1789 - mean_squared_error: 0.6321 - acc: 0.3679 - f1: 0.3073\n",
      "Epoch 54/500\n",
      " - 0s - loss: 10.1494 - mean_squared_error: 0.6302 - acc: 0.3698 - f1: 0.3075\n",
      "Epoch 55/500\n",
      " - 0s - loss: 10.3470 - mean_squared_error: 0.6425 - acc: 0.3575 - f1: 0.2865\n",
      "Epoch 56/500\n",
      " - 0s - loss: 10.1992 - mean_squared_error: 0.6334 - acc: 0.3666 - f1: 0.3054\n",
      "Epoch 57/500\n",
      " - 0s - loss: 10.1761 - mean_squared_error: 0.6319 - acc: 0.3681 - f1: 0.3046\n",
      "Epoch 58/500\n",
      " - 0s - loss: 10.1460 - mean_squared_error: 0.6301 - acc: 0.3699 - f1: 0.3101\n",
      "Epoch 59/500\n",
      " - 0s - loss: 10.3041 - mean_squared_error: 0.6399 - acc: 0.3601 - f1: 0.2955\n",
      "Epoch 60/500\n",
      " - 0s - loss: 10.2573 - mean_squared_error: 0.6370 - acc: 0.3630 - f1: 0.2990\n",
      "Epoch 61/500\n",
      " - 0s - loss: 10.1052 - mean_squared_error: 0.6275 - acc: 0.3725 - f1: 0.3148\n",
      "Epoch 62/500\n",
      " - 0s - loss: 10.2336 - mean_squared_error: 0.6355 - acc: 0.3645 - f1: 0.3031\n",
      "Epoch 63/500\n",
      " - 0s - loss: 10.2411 - mean_squared_error: 0.6360 - acc: 0.3640 - f1: 0.3048\n",
      "Epoch 64/500\n",
      " - 0s - loss: 10.2987 - mean_squared_error: 0.6396 - acc: 0.3604 - f1: 0.3023\n",
      "Epoch 65/500\n",
      " - 0s - loss: 10.1976 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3065\n",
      "Epoch 66/500\n",
      " - 0s - loss: 10.2392 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.3077\n",
      "Epoch 67/500\n",
      " - 0s - loss: 10.1512 - mean_squared_error: 0.6304 - acc: 0.3696 - f1: 0.3185\n",
      "Epoch 68/500\n",
      " - 0s - loss: 10.2609 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.2946\n",
      "Epoch 69/500\n",
      " - 0s - loss: 10.1271 - mean_squared_error: 0.6289 - acc: 0.3711 - f1: 0.3127\n",
      "Epoch 70/500\n",
      " - 0s - loss: 10.2615 - mean_squared_error: 0.6373 - acc: 0.3627 - f1: 0.3026\n",
      "Epoch 71/500\n",
      " - 0s - loss: 10.2116 - mean_squared_error: 0.6341 - acc: 0.3659 - f1: 0.3058\n",
      "Epoch 72/500\n",
      " - 0s - loss: 10.2304 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3036\n",
      "Epoch 73/500\n",
      " - 0s - loss: 10.2209 - mean_squared_error: 0.6347 - acc: 0.3653 - f1: 0.3056\n",
      "Epoch 74/500\n",
      " - 0s - loss: 10.1706 - mean_squared_error: 0.6316 - acc: 0.3684 - f1: 0.3119\n",
      "Epoch 75/500\n",
      " - 0s - loss: 10.2303 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3046\n",
      "Epoch 76/500\n",
      " - 0s - loss: 10.2806 - mean_squared_error: 0.6384 - acc: 0.3616 - f1: 0.2978\n",
      "Epoch 77/500\n",
      " - 0s - loss: 10.1930 - mean_squared_error: 0.6330 - acc: 0.3670 - f1: 0.3060\n",
      "Epoch 78/500\n",
      " - 0s - loss: 10.3418 - mean_squared_error: 0.6422 - acc: 0.3578 - f1: 0.2914\n",
      "Epoch 79/500\n",
      " - 0s - loss: 10.1848 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3096\n",
      "Epoch 80/500\n",
      " - 0s - loss: 10.2257 - mean_squared_error: 0.6350 - acc: 0.3650 - f1: 0.3040\n",
      "Epoch 81/500\n",
      " - 0s - loss: 10.2950 - mean_squared_error: 0.6393 - acc: 0.3607 - f1: 0.2943\n",
      "Epoch 82/500\n",
      " - 0s - loss: 10.2443 - mean_squared_error: 0.6362 - acc: 0.3638 - f1: 0.3042\n",
      "Epoch 83/500\n",
      " - 0s - loss: 10.2175 - mean_squared_error: 0.6345 - acc: 0.3655 - f1: 0.3078\n",
      "Epoch 84/500\n",
      " - 0s - loss: 10.1948 - mean_squared_error: 0.6331 - acc: 0.3669 - f1: 0.3036\n",
      "Epoch 85/500\n",
      " - 0s - loss: 10.2386 - mean_squared_error: 0.6358 - acc: 0.3642 - f1: 0.2997\n",
      "Epoch 86/500\n",
      " - 0s - loss: 10.1752 - mean_squared_error: 0.6319 - acc: 0.3681 - f1: 0.3122\n",
      "Epoch 87/500\n",
      " - 0s - loss: 10.2209 - mean_squared_error: 0.6347 - acc: 0.3653 - f1: 0.3059\n",
      "Epoch 88/500\n",
      " - 0s - loss: 10.2679 - mean_squared_error: 0.6376 - acc: 0.3624 - f1: 0.3007\n",
      "Epoch 89/500\n",
      " - 0s - loss: 10.2850 - mean_squared_error: 0.6387 - acc: 0.3613 - f1: 0.3001\n",
      "Epoch 90/500\n",
      " - 0s - loss: 10.2105 - mean_squared_error: 0.6340 - acc: 0.3660 - f1: 0.3019\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 10.2059 - mean_squared_error: 0.6338 - acc: 0.3662 - f1: 0.3013\n",
      "Epoch 92/500\n",
      " - 0s - loss: 10.2412 - mean_squared_error: 0.6360 - acc: 0.3640 - f1: 0.3040\n",
      "Epoch 93/500\n",
      " - 0s - loss: 10.1652 - mean_squared_error: 0.6312 - acc: 0.3688 - f1: 0.3050\n",
      "Epoch 94/500\n",
      " - 0s - loss: 10.1507 - mean_squared_error: 0.6303 - acc: 0.3697 - f1: 0.3095\n",
      "Epoch 95/500\n",
      " - 0s - loss: 10.2372 - mean_squared_error: 0.6357 - acc: 0.3643 - f1: 0.2988\n",
      "Epoch 96/500\n",
      " - 0s - loss: 10.1754 - mean_squared_error: 0.6319 - acc: 0.3681 - f1: 0.3108\n",
      "Epoch 97/500\n",
      " - 0s - loss: 10.2509 - mean_squared_error: 0.6366 - acc: 0.3634 - f1: 0.3003\n",
      "Epoch 98/500\n",
      " - 0s - loss: 10.1848 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3097\n",
      "Epoch 99/500\n",
      " - 0s - loss: 10.1399 - mean_squared_error: 0.6297 - acc: 0.3703 - f1: 0.3096\n",
      "Epoch 100/500\n",
      " - 0s - loss: 10.2934 - mean_squared_error: 0.6392 - acc: 0.3608 - f1: 0.2948\n",
      "Epoch 101/500\n",
      " - 0s - loss: 10.2756 - mean_squared_error: 0.6381 - acc: 0.3619 - f1: 0.3013\n",
      "Epoch 102/500\n",
      " - 0s - loss: 10.2304 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3036\n",
      "Epoch 103/500\n",
      " - 0s - loss: 10.2135 - mean_squared_error: 0.6342 - acc: 0.3658 - f1: 0.3025\n",
      "Epoch 104/500\n",
      " - 0s - loss: 10.0662 - mean_squared_error: 0.6251 - acc: 0.3749 - f1: 0.3178\n",
      "Epoch 105/500\n",
      " - 0s - loss: 10.2320 - mean_squared_error: 0.6354 - acc: 0.3646 - f1: 0.3036\n",
      "Epoch 106/500\n",
      " - 0s - loss: 10.1088 - mean_squared_error: 0.6277 - acc: 0.3723 - f1: 0.3109\n",
      "Epoch 107/500\n",
      " - 0s - loss: 10.2426 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3054\n",
      "Epoch 108/500\n",
      " - 0s - loss: 10.2599 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.3033\n",
      "Epoch 109/500\n",
      " - 0s - loss: 10.0829 - mean_squared_error: 0.6262 - acc: 0.3738 - f1: 0.3199\n",
      "Epoch 110/500\n",
      " - 0s - loss: 10.3093 - mean_squared_error: 0.6402 - acc: 0.3598 - f1: 0.2913\n",
      "Epoch 111/500\n",
      " - 0s - loss: 10.1835 - mean_squared_error: 0.6324 - acc: 0.3676 - f1: 0.3072\n",
      "Epoch 112/500\n",
      " - 0s - loss: 10.2432 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3003\n",
      "Epoch 113/500\n",
      " - 0s - loss: 10.2398 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.3028\n",
      "Epoch 114/500\n",
      " - 0s - loss: 10.1676 - mean_squared_error: 0.6314 - acc: 0.3686 - f1: 0.3107\n",
      "Epoch 115/500\n",
      " - 0s - loss: 10.3254 - mean_squared_error: 0.6413 - acc: 0.3587 - f1: 0.2988\n",
      "Epoch 116/500\n",
      " - 0s - loss: 10.2418 - mean_squared_error: 0.6360 - acc: 0.3640 - f1: 0.2989\n",
      "Epoch 117/500\n",
      " - 0s - loss: 10.2021 - mean_squared_error: 0.6336 - acc: 0.3664 - f1: 0.3077\n",
      "Epoch 118/500\n",
      " - 0s - loss: 10.1853 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3057\n",
      "Epoch 119/500\n",
      " - 0s - loss: 10.2894 - mean_squared_error: 0.6390 - acc: 0.3610 - f1: 0.3027\n",
      "Epoch 120/500\n",
      " - 0s - loss: 10.0985 - mean_squared_error: 0.6271 - acc: 0.3729 - f1: 0.3194\n",
      "Epoch 121/500\n",
      " - 0s - loss: 10.2701 - mean_squared_error: 0.6377 - acc: 0.3623 - f1: 0.2950\n",
      "Epoch 122/500\n",
      " - 0s - loss: 10.2225 - mean_squared_error: 0.6348 - acc: 0.3652 - f1: 0.3048\n",
      "Epoch 123/500\n",
      " - 0s - loss: 10.1928 - mean_squared_error: 0.6330 - acc: 0.3670 - f1: 0.3078\n",
      "Epoch 124/500\n",
      " - 0s - loss: 10.3833 - mean_squared_error: 0.6449 - acc: 0.3551 - f1: 0.2936\n",
      "Epoch 125/500\n",
      " - 0s - loss: 10.2867 - mean_squared_error: 0.6388 - acc: 0.3612 - f1: 0.2987\n",
      "Epoch 126/500\n",
      " - 0s - loss: 10.1791 - mean_squared_error: 0.6321 - acc: 0.3679 - f1: 0.3051\n",
      "Epoch 127/500\n",
      " - 0s - loss: 10.1976 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3062\n",
      "Epoch 128/500\n",
      " - 0s - loss: 10.1855 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3039\n",
      "Epoch 129/500\n",
      " - 0s - loss: 10.2617 - mean_squared_error: 0.6373 - acc: 0.3627 - f1: 0.3009\n",
      "Epoch 130/500\n",
      " - 0s - loss: 10.3273 - mean_squared_error: 0.6413 - acc: 0.3587 - f1: 0.2961\n",
      "Epoch 131/500\n",
      " - 0s - loss: 10.2146 - mean_squared_error: 0.6343 - acc: 0.3657 - f1: 0.3066\n",
      "Epoch 132/500\n",
      " - 0s - loss: 10.2903 - mean_squared_error: 0.6390 - acc: 0.3610 - f1: 0.2944\n",
      "Epoch 133/500\n",
      " - 0s - loss: 10.2337 - mean_squared_error: 0.6355 - acc: 0.3645 - f1: 0.3023\n",
      "Epoch 134/500\n",
      " - 0s - loss: 10.2300 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3071\n",
      "Epoch 135/500\n",
      " - 0s - loss: 10.0534 - mean_squared_error: 0.6243 - acc: 0.3757 - f1: 0.3209\n",
      "Epoch 136/500\n",
      " - 0s - loss: 10.2067 - mean_squared_error: 0.6338 - acc: 0.3662 - f1: 0.3079\n",
      "Epoch 137/500\n",
      " - 0s - loss: 10.2537 - mean_squared_error: 0.6368 - acc: 0.3632 - f1: 0.3031\n",
      "Epoch 138/500\n",
      " - 0s - loss: 10.2008 - mean_squared_error: 0.6335 - acc: 0.3665 - f1: 0.3055\n",
      "Epoch 139/500\n",
      " - 0s - loss: 10.1287 - mean_squared_error: 0.6290 - acc: 0.3710 - f1: 0.3122\n",
      "Epoch 140/500\n",
      " - 0s - loss: 10.2360 - mean_squared_error: 0.6357 - acc: 0.3643 - f1: 0.3085\n",
      "Epoch 141/500\n",
      " - 0s - loss: 10.2087 - mean_squared_error: 0.6339 - acc: 0.3661 - f1: 0.3037\n",
      "Epoch 142/500\n",
      " - 0s - loss: 10.1475 - mean_squared_error: 0.6301 - acc: 0.3699 - f1: 0.3109\n",
      "Epoch 143/500\n",
      " - 0s - loss: 10.2194 - mean_squared_error: 0.6346 - acc: 0.3654 - f1: 0.3051\n",
      "Epoch 144/500\n",
      " - 0s - loss: 10.2351 - mean_squared_error: 0.6356 - acc: 0.3644 - f1: 0.3029\n",
      "Epoch 145/500\n",
      " - 0s - loss: 10.1019 - mean_squared_error: 0.6273 - acc: 0.3727 - f1: 0.3164\n",
      "Epoch 146/500\n",
      " - 0s - loss: 10.2742 - mean_squared_error: 0.6380 - acc: 0.3620 - f1: 0.3001\n",
      "Epoch 147/500\n",
      " - 0s - loss: 10.2994 - mean_squared_error: 0.6396 - acc: 0.3604 - f1: 0.2959\n",
      "Epoch 148/500\n",
      " - 0s - loss: 10.2301 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3064\n",
      "Epoch 149/500\n",
      " - 0s - loss: 10.2604 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.2989\n",
      "Epoch 150/500\n",
      " - 0s - loss: 10.1289 - mean_squared_error: 0.6290 - acc: 0.3710 - f1: 0.3106\n",
      "Epoch 151/500\n",
      " - 0s - loss: 10.1975 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3074\n",
      "Epoch 152/500\n",
      " - 0s - loss: 10.2661 - mean_squared_error: 0.6375 - acc: 0.3625 - f1: 0.3028\n",
      "Epoch 153/500\n",
      " - 0s - loss: 10.3553 - mean_squared_error: 0.6431 - acc: 0.3569 - f1: 0.2953\n",
      "Epoch 154/500\n",
      " - 0s - loss: 10.1426 - mean_squared_error: 0.6299 - acc: 0.3701 - f1: 0.3134\n",
      "Epoch 155/500\n",
      " - 0s - loss: 10.1427 - mean_squared_error: 0.6299 - acc: 0.3701 - f1: 0.3122\n",
      "Epoch 156/500\n",
      " - 0s - loss: 10.1726 - mean_squared_error: 0.6317 - acc: 0.3683 - f1: 0.3081\n",
      "Epoch 157/500\n",
      " - 0s - loss: 10.2349 - mean_squared_error: 0.6356 - acc: 0.3644 - f1: 0.3053\n",
      "Epoch 158/500\n",
      " - 0s - loss: 10.2213 - mean_squared_error: 0.6347 - acc: 0.3653 - f1: 0.3023\n",
      "Epoch 159/500\n",
      " - 0s - loss: 10.2133 - mean_squared_error: 0.6342 - acc: 0.3658 - f1: 0.3047\n",
      "Epoch 160/500\n",
      " - 0s - loss: 10.2713 - mean_squared_error: 0.6378 - acc: 0.3622 - f1: 0.2986\n",
      "Epoch 161/500\n",
      " - 0s - loss: 10.2760 - mean_squared_error: 0.6381 - acc: 0.3619 - f1: 0.2980\n",
      "Epoch 162/500\n",
      " - 0s - loss: 10.1622 - mean_squared_error: 0.6310 - acc: 0.3690 - f1: 0.3046\n",
      "Epoch 163/500\n",
      " - 0s - loss: 10.2385 - mean_squared_error: 0.6358 - acc: 0.3642 - f1: 0.3010\n",
      "Epoch 164/500\n",
      " - 0s - loss: 10.1178 - mean_squared_error: 0.6283 - acc: 0.3717 - f1: 0.3127\n",
      "Epoch 165/500\n",
      " - 0s - loss: 10.1990 - mean_squared_error: 0.6334 - acc: 0.3666 - f1: 0.3071\n",
      "Epoch 166/500\n",
      " - 0s - loss: 10.3213 - mean_squared_error: 0.6410 - acc: 0.3590 - f1: 0.2945\n",
      "Epoch 167/500\n",
      " - 0s - loss: 10.1284 - mean_squared_error: 0.6290 - acc: 0.3710 - f1: 0.3156\n",
      "Epoch 168/500\n",
      " - 0s - loss: 10.2474 - mean_squared_error: 0.6364 - acc: 0.3636 - f1: 0.3041\n",
      "Epoch 169/500\n",
      " - 0s - loss: 10.2959 - mean_squared_error: 0.6394 - acc: 0.3606 - f1: 0.2997\n",
      "Epoch 170/500\n",
      " - 0s - loss: 10.2520 - mean_squared_error: 0.6367 - acc: 0.3633 - f1: 0.3043\n",
      "Epoch 171/500\n",
      " - 0s - loss: 10.1535 - mean_squared_error: 0.6305 - acc: 0.3695 - f1: 0.3121\n",
      "Epoch 172/500\n",
      " - 0s - loss: 10.1461 - mean_squared_error: 0.6301 - acc: 0.3699 - f1: 0.3094\n",
      "Epoch 173/500\n",
      " - 0s - loss: 10.1929 - mean_squared_error: 0.6330 - acc: 0.3670 - f1: 0.3066\n",
      "Epoch 174/500\n",
      " - 0s - loss: 10.1644 - mean_squared_error: 0.6312 - acc: 0.3688 - f1: 0.3119\n",
      "Epoch 175/500\n",
      " - 0s - loss: 10.2136 - mean_squared_error: 0.6342 - acc: 0.3658 - f1: 0.3020\n",
      "Epoch 176/500\n",
      " - 0s - loss: 10.2570 - mean_squared_error: 0.6370 - acc: 0.3630 - f1: 0.3012\n",
      "Epoch 177/500\n",
      " - 0s - loss: 10.2757 - mean_squared_error: 0.6381 - acc: 0.3619 - f1: 0.3006\n",
      "Epoch 178/500\n",
      " - 0s - loss: 10.2181 - mean_squared_error: 0.6345 - acc: 0.3655 - f1: 0.3028\n",
      "Epoch 179/500\n",
      " - 0s - loss: 10.2591 - mean_squared_error: 0.6371 - acc: 0.3629 - f1: 0.2967\n",
      "Epoch 180/500\n",
      " - 0s - loss: 10.1523 - mean_squared_error: 0.6304 - acc: 0.3696 - f1: 0.3092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      " - 0s - loss: 10.3632 - mean_squared_error: 0.6436 - acc: 0.3564 - f1: 0.2932\n",
      "Epoch 182/500\n",
      " - 0s - loss: 10.2102 - mean_squared_error: 0.6340 - acc: 0.3660 - f1: 0.3043\n",
      "Epoch 183/500\n",
      " - 0s - loss: 10.2540 - mean_squared_error: 0.6368 - acc: 0.3632 - f1: 0.3001\n",
      "Epoch 184/500\n",
      " - 0s - loss: 10.1288 - mean_squared_error: 0.6290 - acc: 0.3710 - f1: 0.3119\n",
      "Epoch 185/500\n",
      " - 0s - loss: 10.2227 - mean_squared_error: 0.6348 - acc: 0.3652 - f1: 0.3033\n",
      "Epoch 186/500\n",
      " - 0s - loss: 10.2093 - mean_squared_error: 0.6339 - acc: 0.3661 - f1: 0.2988\n",
      "Epoch 187/500\n",
      " - 0s - loss: 10.1828 - mean_squared_error: 0.6324 - acc: 0.3676 - f1: 0.3134\n",
      "Epoch 188/500\n",
      " - 0s - loss: 10.2616 - mean_squared_error: 0.6373 - acc: 0.3627 - f1: 0.3020\n",
      "Epoch 189/500\n",
      " - 0s - loss: 10.1069 - mean_squared_error: 0.6276 - acc: 0.3724 - f1: 0.3133\n",
      "Epoch 190/500\n",
      " - 0s - loss: 10.2051 - mean_squared_error: 0.6338 - acc: 0.3662 - f1: 0.3078\n",
      "Epoch 191/500\n",
      " - 0s - loss: 10.2377 - mean_squared_error: 0.6358 - acc: 0.3642 - f1: 0.3074\n",
      "Epoch 192/500\n",
      " - 0s - loss: 10.2557 - mean_squared_error: 0.6369 - acc: 0.3631 - f1: 0.2992\n",
      "Epoch 193/500\n",
      " - 0s - loss: 10.1010 - mean_squared_error: 0.6272 - acc: 0.3728 - f1: 0.3115\n",
      "Epoch 194/500\n",
      " - 0s - loss: 10.1975 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3066\n",
      "Epoch 195/500\n",
      " - 0s - loss: 10.1913 - mean_squared_error: 0.6329 - acc: 0.3671 - f1: 0.3071\n",
      "Epoch 196/500\n",
      " - 0s - loss: 10.2661 - mean_squared_error: 0.6375 - acc: 0.3625 - f1: 0.3030\n",
      "Epoch 197/500\n",
      " - 0s - loss: 10.1330 - mean_squared_error: 0.6293 - acc: 0.3707 - f1: 0.3156\n",
      "Epoch 198/500\n",
      " - 0s - loss: 10.2370 - mean_squared_error: 0.6357 - acc: 0.3643 - f1: 0.3003\n",
      "Epoch 199/500\n",
      " - 0s - loss: 10.3353 - mean_squared_error: 0.6418 - acc: 0.3582 - f1: 0.2938\n",
      "Epoch 200/500\n",
      " - 0s - loss: 10.2525 - mean_squared_error: 0.6367 - acc: 0.3633 - f1: 0.2999\n",
      "Epoch 201/500\n",
      " - 0s - loss: 10.1258 - mean_squared_error: 0.6288 - acc: 0.3712 - f1: 0.3105\n",
      "Epoch 202/500\n",
      " - 0s - loss: 10.1864 - mean_squared_error: 0.6326 - acc: 0.3674 - f1: 0.3094\n",
      "Epoch 203/500\n",
      " - 0s - loss: 10.3103 - mean_squared_error: 0.6403 - acc: 0.3597 - f1: 0.2960\n",
      "Epoch 204/500\n",
      " - 0s - loss: 10.2400 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.3009\n",
      "Epoch 205/500\n",
      " - 0s - loss: 10.1643 - mean_squared_error: 0.6312 - acc: 0.3688 - f1: 0.3125\n",
      "Epoch 206/500\n",
      " - 0s - loss: 10.2024 - mean_squared_error: 0.6336 - acc: 0.3664 - f1: 0.3049\n",
      "Epoch 207/500\n",
      " - 0s - loss: 10.1647 - mean_squared_error: 0.6312 - acc: 0.3688 - f1: 0.3094\n",
      "Epoch 208/500\n",
      " - 0s - loss: 10.1219 - mean_squared_error: 0.6286 - acc: 0.3714 - f1: 0.3179\n",
      "Epoch 209/500\n",
      " - 0s - loss: 10.2771 - mean_squared_error: 0.6382 - acc: 0.3618 - f1: 0.3019\n",
      "Epoch 210/500\n",
      " - 0s - loss: 10.0879 - mean_squared_error: 0.6264 - acc: 0.3736 - f1: 0.3175\n",
      "Epoch 211/500\n",
      " - 0s - loss: 10.1758 - mean_squared_error: 0.6319 - acc: 0.3681 - f1: 0.3074\n",
      "Epoch 212/500\n",
      " - 0s - loss: 10.2197 - mean_squared_error: 0.6346 - acc: 0.3654 - f1: 0.3022\n",
      "Epoch 213/500\n",
      " - 0s - loss: 10.2303 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3045\n",
      "Epoch 214/500\n",
      " - 0s - loss: 10.1730 - mean_squared_error: 0.6317 - acc: 0.3683 - f1: 0.3045\n",
      "Epoch 215/500\n",
      " - 0s - loss: 10.1926 - mean_squared_error: 0.6330 - acc: 0.3670 - f1: 0.3094\n",
      "Epoch 216/500\n",
      " - 0s - loss: 10.2819 - mean_squared_error: 0.6385 - acc: 0.3615 - f1: 0.3001\n",
      "Epoch 217/500\n",
      " - 0s - loss: 10.2315 - mean_squared_error: 0.6354 - acc: 0.3646 - f1: 0.3074\n",
      "Epoch 218/500\n",
      " - 0s - loss: 10.2255 - mean_squared_error: 0.6350 - acc: 0.3650 - f1: 0.3058\n",
      "Epoch 219/500\n",
      " - 0s - loss: 10.0431 - mean_squared_error: 0.6236 - acc: 0.3764 - f1: 0.3167\n",
      "Epoch 220/500\n",
      " - 0s - loss: 10.2160 - mean_squared_error: 0.6344 - acc: 0.3656 - f1: 0.3076\n",
      "Epoch 221/500\n",
      " - 0s - loss: 10.1581 - mean_squared_error: 0.6308 - acc: 0.3692 - f1: 0.3128\n",
      "Epoch 222/500\n",
      " - 0s - loss: 10.3351 - mean_squared_error: 0.6418 - acc: 0.3582 - f1: 0.2956\n",
      "Epoch 223/500\n",
      " - 0s - loss: 10.2368 - mean_squared_error: 0.6357 - acc: 0.3643 - f1: 0.3017\n",
      "Epoch 224/500\n",
      " - 0s - loss: 10.1905 - mean_squared_error: 0.6329 - acc: 0.3671 - f1: 0.3137\n",
      "Epoch 225/500\n",
      " - 0s - loss: 10.2036 - mean_squared_error: 0.6337 - acc: 0.3663 - f1: 0.3078\n",
      "Epoch 226/500\n",
      " - 0s - loss: 10.1817 - mean_squared_error: 0.6323 - acc: 0.3677 - f1: 0.3096\n",
      "Epoch 227/500\n",
      " - 0s - loss: 10.1912 - mean_squared_error: 0.6329 - acc: 0.3671 - f1: 0.3082\n",
      "Epoch 228/500\n",
      " - 0s - loss: 10.2135 - mean_squared_error: 0.6342 - acc: 0.3658 - f1: 0.3022\n",
      "Epoch 229/500\n",
      " - 0s - loss: 10.2597 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.3047\n",
      "Epoch 230/500\n",
      " - 0s - loss: 10.2332 - mean_squared_error: 0.6355 - acc: 0.3645 - f1: 0.3059\n",
      "Epoch 231/500\n",
      " - 0s - loss: 10.1018 - mean_squared_error: 0.6273 - acc: 0.3727 - f1: 0.3173\n",
      "Epoch 232/500\n",
      " - 0s - loss: 10.1522 - mean_squared_error: 0.6304 - acc: 0.3696 - f1: 0.3107\n",
      "Epoch 233/500\n",
      " - 0s - loss: 10.2929 - mean_squared_error: 0.6392 - acc: 0.3608 - f1: 0.2992\n",
      "Epoch 234/500\n",
      " - 0s - loss: 10.1816 - mean_squared_error: 0.6323 - acc: 0.3677 - f1: 0.3104\n",
      "Epoch 235/500\n",
      " - 0s - loss: 10.1945 - mean_squared_error: 0.6331 - acc: 0.3669 - f1: 0.3064\n",
      "Epoch 236/500\n",
      " - 0s - loss: 10.2177 - mean_squared_error: 0.6345 - acc: 0.3655 - f1: 0.3061\n",
      "Epoch 237/500\n",
      " - 0s - loss: 10.3401 - mean_squared_error: 0.6421 - acc: 0.3579 - f1: 0.2923\n",
      "Epoch 238/500\n",
      " - 0s - loss: 10.1850 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3079\n",
      "Epoch 239/500\n",
      " - 0s - loss: 10.1852 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3065\n",
      "Epoch 240/500\n",
      " - 0s - loss: 10.1099 - mean_squared_error: 0.6278 - acc: 0.3722 - f1: 0.3145\n",
      "Epoch 241/500\n",
      " - 0s - loss: 10.1947 - mean_squared_error: 0.6331 - acc: 0.3669 - f1: 0.3046\n",
      "Epoch 242/500\n",
      " - 0s - loss: 10.1709 - mean_squared_error: 0.6316 - acc: 0.3684 - f1: 0.3094\n",
      "Epoch 243/500\n",
      " - 0s - loss: 10.2400 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.3015\n",
      "Epoch 244/500\n",
      " - 0s - loss: 10.1850 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3076\n",
      "Epoch 245/500\n",
      " - 0s - loss: 10.2221 - mean_squared_error: 0.6348 - acc: 0.3652 - f1: 0.3083\n",
      "Epoch 246/500\n",
      " - 0s - loss: 10.2678 - mean_squared_error: 0.6376 - acc: 0.3624 - f1: 0.3018\n",
      "Epoch 247/500\n",
      " - 0s - loss: 10.2258 - mean_squared_error: 0.6350 - acc: 0.3650 - f1: 0.3034\n",
      "Epoch 248/500\n",
      " - 0s - loss: 10.2869 - mean_squared_error: 0.6388 - acc: 0.3612 - f1: 0.2973\n",
      "Epoch 249/500\n",
      " - 0s - loss: 10.1677 - mean_squared_error: 0.6314 - acc: 0.3686 - f1: 0.3101\n",
      "Epoch 250/500\n",
      " - 0s - loss: 10.0582 - mean_squared_error: 0.6246 - acc: 0.3754 - f1: 0.3200\n",
      "Epoch 251/500\n",
      " - 0s - loss: 10.2715 - mean_squared_error: 0.6378 - acc: 0.3622 - f1: 0.2963\n",
      "Epoch 252/500\n",
      " - 0s - loss: 10.2303 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3046\n",
      "Epoch 253/500\n",
      " - 0s - loss: 10.2948 - mean_squared_error: 0.6393 - acc: 0.3607 - f1: 0.2958\n",
      "Epoch 254/500\n",
      " - 0s - loss: 10.2304 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3034\n",
      "Epoch 255/500\n",
      " - 0s - loss: 10.1604 - mean_squared_error: 0.6309 - acc: 0.3691 - f1: 0.3061\n",
      "Epoch 256/500\n",
      " - 0s - loss: 10.2551 - mean_squared_error: 0.6369 - acc: 0.3631 - f1: 0.3041\n",
      "Epoch 257/500\n",
      " - 0s - loss: 10.1774 - mean_squared_error: 0.6320 - acc: 0.3680 - f1: 0.3065\n",
      "Epoch 258/500\n",
      " - 0s - loss: 10.1834 - mean_squared_error: 0.6324 - acc: 0.3676 - f1: 0.3087\n",
      "Epoch 259/500\n",
      " - 0s - loss: 10.1741 - mean_squared_error: 0.6318 - acc: 0.3682 - f1: 0.3086\n",
      "Epoch 260/500\n",
      " - 0s - loss: 10.1694 - mean_squared_error: 0.6315 - acc: 0.3685 - f1: 0.3089\n",
      "Epoch 261/500\n",
      " - 0s - loss: 10.1641 - mean_squared_error: 0.6312 - acc: 0.3688 - f1: 0.3145\n",
      "Epoch 262/500\n",
      " - 0s - loss: 10.0972 - mean_squared_error: 0.6270 - acc: 0.3730 - f1: 0.3168\n",
      "Epoch 263/500\n",
      " - 0s - loss: 10.1823 - mean_squared_error: 0.6323 - acc: 0.3677 - f1: 0.3043\n",
      "Epoch 264/500\n",
      " - 0s - loss: 10.1930 - mean_squared_error: 0.6330 - acc: 0.3670 - f1: 0.3060\n",
      "Epoch 265/500\n",
      " - 0s - loss: 10.2510 - mean_squared_error: 0.6366 - acc: 0.3634 - f1: 0.3000\n",
      "Epoch 266/500\n",
      " - 0s - loss: 10.2370 - mean_squared_error: 0.6357 - acc: 0.3643 - f1: 0.2999\n",
      "Epoch 267/500\n",
      " - 0s - loss: 10.1648 - mean_squared_error: 0.6312 - acc: 0.3688 - f1: 0.3088\n",
      "Epoch 268/500\n",
      " - 0s - loss: 10.1892 - mean_squared_error: 0.6328 - acc: 0.3672 - f1: 0.3119\n",
      "Epoch 269/500\n",
      " - 0s - loss: 10.1275 - mean_squared_error: 0.6289 - acc: 0.3711 - f1: 0.3096\n",
      "Epoch 270/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 10.1603 - mean_squared_error: 0.6309 - acc: 0.3691 - f1: 0.3068\n",
      "Epoch 271/500\n",
      " - 0s - loss: 10.1317 - mean_squared_error: 0.6292 - acc: 0.3708 - f1: 0.3133\n",
      "Epoch 272/500\n",
      " - 0s - loss: 10.1981 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3022\n",
      "Epoch 273/500\n",
      " - 0s - loss: 10.1504 - mean_squared_error: 0.6303 - acc: 0.3697 - f1: 0.3120\n",
      "Epoch 274/500\n",
      " - 0s - loss: 10.2039 - mean_squared_error: 0.6337 - acc: 0.3663 - f1: 0.3053\n",
      "Epoch 275/500\n",
      " - 0s - loss: 10.3051 - mean_squared_error: 0.6400 - acc: 0.3600 - f1: 0.3007\n",
      "Epoch 276/500\n",
      " - 0s - loss: 10.1490 - mean_squared_error: 0.6302 - acc: 0.3698 - f1: 0.3113\n",
      "Epoch 277/500\n",
      " - 0s - loss: 10.2428 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3036\n",
      "Epoch 278/500\n",
      " - 0s - loss: 10.1724 - mean_squared_error: 0.6317 - acc: 0.3683 - f1: 0.3100\n",
      "Epoch 279/500\n",
      " - 0s - loss: 10.2337 - mean_squared_error: 0.6355 - acc: 0.3645 - f1: 0.3023\n",
      "Epoch 280/500\n",
      " - 0s - loss: 10.3170 - mean_squared_error: 0.6407 - acc: 0.3593 - f1: 0.2908\n",
      "Epoch 281/500\n",
      " - 0s - loss: 10.2565 - mean_squared_error: 0.6370 - acc: 0.3630 - f1: 0.3057\n",
      "Epoch 282/500\n",
      " - 0s - loss: 10.1977 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3050\n",
      "Epoch 283/500\n",
      " - 0s - loss: 10.2962 - mean_squared_error: 0.6394 - acc: 0.3606 - f1: 0.2970\n",
      "Epoch 284/500\n",
      " - 0s - loss: 10.1174 - mean_squared_error: 0.6283 - acc: 0.3717 - f1: 0.3162\n",
      "Epoch 285/500\n",
      " - 0s - loss: 10.1499 - mean_squared_error: 0.6303 - acc: 0.3697 - f1: 0.3165\n",
      "Epoch 286/500\n",
      " - 0s - loss: 10.2487 - mean_squared_error: 0.6365 - acc: 0.3635 - f1: 0.3059\n",
      "Epoch 287/500\n",
      " - 0s - loss: 10.2290 - mean_squared_error: 0.6352 - acc: 0.3648 - f1: 0.3021\n",
      "Epoch 288/500\n",
      " - 0s - loss: 10.1413 - mean_squared_error: 0.6298 - acc: 0.3702 - f1: 0.3108\n",
      "Epoch 289/500\n",
      " - 0s - loss: 10.2609 - mean_squared_error: 0.6373 - acc: 0.3627 - f1: 0.3080\n",
      "Epoch 290/500\n",
      " - 0s - loss: 10.2903 - mean_squared_error: 0.6390 - acc: 0.3610 - f1: 0.2949\n",
      "Epoch 291/500\n",
      " - 0s - loss: 10.2431 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3008\n",
      "Epoch 292/500\n",
      " - 0s - loss: 10.1980 - mean_squared_error: 0.6333 - acc: 0.3667 - f1: 0.3029\n",
      "Epoch 293/500\n",
      " - 0s - loss: 10.0146 - mean_squared_error: 0.6219 - acc: 0.3781 - f1: 0.3216\n",
      "Epoch 294/500\n",
      " - 0s - loss: 10.2565 - mean_squared_error: 0.6370 - acc: 0.3630 - f1: 0.3058\n",
      "Epoch 295/500\n",
      " - 0s - loss: 10.3301 - mean_squared_error: 0.6415 - acc: 0.3585 - f1: 0.2986\n",
      "Epoch 296/500\n",
      " - 0s - loss: 10.1114 - mean_squared_error: 0.6279 - acc: 0.3721 - f1: 0.3151\n",
      "Epoch 297/500\n",
      " - 0s - loss: 10.1495 - mean_squared_error: 0.6302 - acc: 0.3698 - f1: 0.3066\n",
      "Epoch 298/500\n",
      " - 0s - loss: 10.1413 - mean_squared_error: 0.6298 - acc: 0.3702 - f1: 0.3106\n",
      "Epoch 299/500\n",
      " - 0s - loss: 10.1789 - mean_squared_error: 0.6321 - acc: 0.3679 - f1: 0.3073\n",
      "Epoch 300/500\n",
      " - 0s - loss: 10.1735 - mean_squared_error: 0.6318 - acc: 0.3682 - f1: 0.3131\n",
      "Epoch 301/500\n",
      " - 0s - loss: 10.2773 - mean_squared_error: 0.6382 - acc: 0.3618 - f1: 0.2996\n",
      "Epoch 302/500\n",
      " - 0s - loss: 10.3005 - mean_squared_error: 0.6397 - acc: 0.3603 - f1: 0.2998\n",
      "Epoch 303/500\n",
      " - 0s - loss: 10.1563 - mean_squared_error: 0.6307 - acc: 0.3693 - f1: 0.3153\n",
      "Epoch 304/500\n",
      " - 0s - loss: 10.1845 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3123\n",
      "Epoch 305/500\n",
      " - 0s - loss: 10.1477 - mean_squared_error: 0.6301 - acc: 0.3699 - f1: 0.3089\n",
      "Epoch 306/500\n",
      " - 0s - loss: 10.2432 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3005\n",
      "Epoch 307/500\n",
      " - 0s - loss: 10.2035 - mean_squared_error: 0.6337 - acc: 0.3663 - f1: 0.3084\n",
      "Epoch 308/500\n",
      " - 0s - loss: 10.3007 - mean_squared_error: 0.6397 - acc: 0.3603 - f1: 0.2983\n",
      "Epoch 309/500\n",
      " - 0s - loss: 10.2304 - mean_squared_error: 0.6353 - acc: 0.3647 - f1: 0.3040\n",
      "Epoch 310/500\n",
      " - 0s - loss: 10.1594 - mean_squared_error: 0.6309 - acc: 0.3691 - f1: 0.3148\n",
      "Epoch 311/500\n",
      " - 0s - loss: 10.2044 - mean_squared_error: 0.6337 - acc: 0.3663 - f1: 0.3010\n",
      "Epoch 312/500\n",
      " - 0s - loss: 10.0588 - mean_squared_error: 0.6246 - acc: 0.3754 - f1: 0.3147\n",
      "Epoch 313/500\n",
      " - 0s - loss: 10.2494 - mean_squared_error: 0.6365 - acc: 0.3635 - f1: 0.3004\n",
      "Epoch 314/500\n",
      " - 0s - loss: 10.1163 - mean_squared_error: 0.6282 - acc: 0.3718 - f1: 0.3128\n",
      "Epoch 315/500\n",
      " - 0s - loss: 10.2270 - mean_squared_error: 0.6351 - acc: 0.3649 - f1: 0.3060\n",
      "Epoch 316/500\n",
      " - 0s - loss: 10.2585 - mean_squared_error: 0.6371 - acc: 0.3629 - f1: 0.3018\n",
      "Epoch 317/500\n",
      " - 0s - loss: 10.2395 - mean_squared_error: 0.6359 - acc: 0.3641 - f1: 0.3055\n",
      "Epoch 318/500\n",
      " - 0s - loss: 10.2853 - mean_squared_error: 0.6387 - acc: 0.3613 - f1: 0.2980\n",
      "Epoch 319/500\n",
      " - 0s - loss: 10.2334 - mean_squared_error: 0.6355 - acc: 0.3645 - f1: 0.3043\n",
      "Epoch 320/500\n",
      " - 0s - loss: 10.3321 - mean_squared_error: 0.6416 - acc: 0.3584 - f1: 0.2951\n",
      "Epoch 321/500\n",
      " - 0s - loss: 10.1796 - mean_squared_error: 0.6322 - acc: 0.3678 - f1: 0.3140\n",
      "Epoch 322/500\n",
      " - 0s - loss: 10.2606 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.2965\n",
      "Epoch 323/500\n",
      " - 0s - loss: 10.1336 - mean_squared_error: 0.6293 - acc: 0.3707 - f1: 0.3102\n",
      "Epoch 324/500\n",
      " - 0s - loss: 10.2727 - mean_squared_error: 0.6379 - acc: 0.3621 - f1: 0.2993\n",
      "Epoch 325/500\n",
      " - 0s - loss: 10.2174 - mean_squared_error: 0.6345 - acc: 0.3655 - f1: 0.3089\n",
      "Epoch 326/500\n",
      " - 0s - loss: 10.1944 - mean_squared_error: 0.6331 - acc: 0.3669 - f1: 0.3070\n",
      "Epoch 327/500\n",
      " - 0s - loss: 10.2082 - mean_squared_error: 0.6339 - acc: 0.3661 - f1: 0.3082\n",
      "Epoch 328/500\n",
      " - 0s - loss: 10.1237 - mean_squared_error: 0.6287 - acc: 0.3713 - f1: 0.3154\n",
      "Epoch 329/500\n",
      " - 0s - loss: 10.2146 - mean_squared_error: 0.6343 - acc: 0.3657 - f1: 0.3063\n",
      "Epoch 330/500\n",
      " - 0s - loss: 10.1761 - mean_squared_error: 0.6319 - acc: 0.3681 - f1: 0.3047\n",
      "Epoch 331/500\n",
      " - 0s - loss: 10.2355 - mean_squared_error: 0.6356 - acc: 0.3644 - f1: 0.3001\n",
      "Epoch 332/500\n",
      " - 0s - loss: 10.2966 - mean_squared_error: 0.6394 - acc: 0.3606 - f1: 0.2940\n",
      "Epoch 333/500\n",
      " - 0s - loss: 10.1831 - mean_squared_error: 0.6324 - acc: 0.3676 - f1: 0.3112\n",
      "Epoch 334/500\n",
      " - 0s - loss: 10.2711 - mean_squared_error: 0.6378 - acc: 0.3622 - f1: 0.3004\n",
      "Epoch 335/500\n",
      " - 0s - loss: 10.2581 - mean_squared_error: 0.6371 - acc: 0.3629 - f1: 0.3051\n",
      "Epoch 336/500\n",
      " - 0s - loss: 10.1519 - mean_squared_error: 0.6304 - acc: 0.3696 - f1: 0.3129\n",
      "Epoch 337/500\n",
      " - 0s - loss: 10.1694 - mean_squared_error: 0.6315 - acc: 0.3685 - f1: 0.3087\n",
      "Epoch 338/500\n",
      " - 0s - loss: 10.0597 - mean_squared_error: 0.6247 - acc: 0.3753 - f1: 0.3202\n",
      "Epoch 339/500\n",
      " - 0s - loss: 10.1635 - mean_squared_error: 0.6311 - acc: 0.3689 - f1: 0.3060\n",
      "Epoch 340/500\n",
      " - 0s - loss: 10.2535 - mean_squared_error: 0.6368 - acc: 0.3632 - f1: 0.3046\n",
      "Epoch 341/500\n",
      " - 0s - loss: 10.1681 - mean_squared_error: 0.6314 - acc: 0.3686 - f1: 0.3064\n",
      "Epoch 342/500\n",
      " - 0s - loss: 10.2290 - mean_squared_error: 0.6352 - acc: 0.3648 - f1: 0.3020\n",
      "Epoch 343/500\n",
      " - 0s - loss: 10.2849 - mean_squared_error: 0.6387 - acc: 0.3613 - f1: 0.3008\n",
      "Epoch 344/500\n",
      " - 0s - loss: 10.1375 - mean_squared_error: 0.6296 - acc: 0.3704 - f1: 0.3165\n",
      "Epoch 345/500\n",
      " - 0s - loss: 10.1848 - mean_squared_error: 0.6325 - acc: 0.3675 - f1: 0.3099\n",
      "Epoch 346/500\n",
      " - 0s - loss: 10.0836 - mean_squared_error: 0.6262 - acc: 0.3738 - f1: 0.3146\n",
      "Epoch 347/500\n",
      " - 0s - loss: 10.2433 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.2991\n",
      "Epoch 348/500\n",
      " - 0s - loss: 10.1696 - mean_squared_error: 0.6315 - acc: 0.3685 - f1: 0.3069\n",
      "Epoch 349/500\n",
      " - 0s - loss: 10.1861 - mean_squared_error: 0.6326 - acc: 0.3674 - f1: 0.3120\n",
      "Epoch 350/500\n",
      " - 0s - loss: 10.0689 - mean_squared_error: 0.6253 - acc: 0.3747 - f1: 0.3203\n",
      "Epoch 351/500\n",
      " - 0s - loss: 10.2797 - mean_squared_error: 0.6384 - acc: 0.3616 - f1: 0.3058\n",
      "Epoch 352/500\n",
      " - 0s - loss: 10.2680 - mean_squared_error: 0.6376 - acc: 0.3624 - f1: 0.2997\n",
      "Epoch 353/500\n",
      " - 0s - loss: 10.2239 - mean_squared_error: 0.6349 - acc: 0.3651 - f1: 0.3059\n",
      "Epoch 354/500\n",
      " - 0s - loss: 10.2635 - mean_squared_error: 0.6374 - acc: 0.3626 - f1: 0.2989\n",
      "Epoch 355/500\n",
      " - 0s - loss: 10.2680 - mean_squared_error: 0.6376 - acc: 0.3624 - f1: 0.3003\n",
      "Epoch 356/500\n",
      " - 0s - loss: 10.1783 - mean_squared_error: 0.6321 - acc: 0.3679 - f1: 0.3125\n",
      "Epoch 357/500\n",
      " - 0s - loss: 10.2177 - mean_squared_error: 0.6345 - acc: 0.3655 - f1: 0.3061\n",
      "Epoch 358/500\n",
      " - 0s - loss: 10.3150 - mean_squared_error: 0.6406 - acc: 0.3594 - f1: 0.2956\n",
      "Epoch 359/500\n",
      " - 0s - loss: 10.2653 - mean_squared_error: 0.6375 - acc: 0.3625 - f1: 0.2967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      " - 0s - loss: 10.1869 - mean_squared_error: 0.6326 - acc: 0.3674 - f1: 0.3051\n",
      "Epoch 361/500\n",
      " - 0s - loss: 10.2432 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.2999\n",
      "Epoch 362/500\n",
      " - 0s - loss: 10.1956 - mean_squared_error: 0.6332 - acc: 0.3668 - f1: 0.3099\n",
      "Epoch 363/500\n",
      " - 0s - loss: 10.1100 - mean_squared_error: 0.6278 - acc: 0.3722 - f1: 0.3133\n",
      "Epoch 364/500\n",
      " - 0s - loss: 10.1583 - mean_squared_error: 0.6308 - acc: 0.3692 - f1: 0.3114\n",
      "Epoch 365/500\n",
      " - 0s - loss: 10.2132 - mean_squared_error: 0.6342 - acc: 0.3658 - f1: 0.3054\n",
      "Epoch 366/500\n",
      " - 0s - loss: 10.3100 - mean_squared_error: 0.6403 - acc: 0.3597 - f1: 0.2982\n",
      "Epoch 367/500\n",
      " - 0s - loss: 10.1131 - mean_squared_error: 0.6280 - acc: 0.3720 - f1: 0.3137\n",
      "Epoch 368/500\n",
      " - 0s - loss: 10.2142 - mean_squared_error: 0.6343 - acc: 0.3657 - f1: 0.3095\n",
      "Epoch 369/500\n",
      " - 0s - loss: 10.2572 - mean_squared_error: 0.6370 - acc: 0.3630 - f1: 0.2992\n",
      "Epoch 370/500\n",
      " - 0s - loss: 10.2279 - mean_squared_error: 0.6352 - acc: 0.3648 - f1: 0.3116\n",
      "Epoch 371/500\n",
      " - 0s - loss: 10.1772 - mean_squared_error: 0.6320 - acc: 0.3680 - f1: 0.3084\n",
      "Epoch 372/500\n",
      " - 0s - loss: 10.2959 - mean_squared_error: 0.6394 - acc: 0.3606 - f1: 0.3000\n",
      "Epoch 373/500\n",
      " - 0s - loss: 10.2868 - mean_squared_error: 0.6388 - acc: 0.3612 - f1: 0.2978\n",
      "Epoch 374/500\n",
      " - 0s - loss: 10.2897 - mean_squared_error: 0.6390 - acc: 0.3610 - f1: 0.2997\n",
      "Epoch 375/500\n",
      " - 0s - loss: 10.2099 - mean_squared_error: 0.6340 - acc: 0.3660 - f1: 0.3073\n",
      "Epoch 376/500\n",
      " - 0s - loss: 10.1196 - mean_squared_error: 0.6284 - acc: 0.3716 - f1: 0.3114\n",
      "Epoch 377/500\n",
      " - 0s - loss: 10.2180 - mean_squared_error: 0.6345 - acc: 0.3655 - f1: 0.3037\n",
      "Epoch 378/500\n",
      " - 0s - loss: 10.1524 - mean_squared_error: 0.6304 - acc: 0.3696 - f1: 0.3082\n",
      "Epoch 379/500\n",
      " - 0s - loss: 10.1582 - mean_squared_error: 0.6308 - acc: 0.3692 - f1: 0.3116\n",
      "Epoch 380/500\n",
      " - 0s - loss: 10.1684 - mean_squared_error: 0.6314 - acc: 0.3686 - f1: 0.3041\n",
      "Epoch 381/500\n",
      " - 0s - loss: 10.2274 - mean_squared_error: 0.6351 - acc: 0.3649 - f1: 0.3031\n",
      "Epoch 382/500\n",
      " - 0s - loss: 10.3072 - mean_squared_error: 0.6401 - acc: 0.3599 - f1: 0.2962\n",
      "Epoch 383/500\n",
      " - 0s - loss: 10.1993 - mean_squared_error: 0.6334 - acc: 0.3666 - f1: 0.3051\n",
      "Epoch 384/500\n",
      " - 0s - loss: 10.1492 - mean_squared_error: 0.6302 - acc: 0.3698 - f1: 0.3097\n",
      "Epoch 385/500\n",
      " - 0s - loss: 10.1236 - mean_squared_error: 0.6287 - acc: 0.3713 - f1: 0.3161\n",
      "Epoch 386/500\n",
      " - 0s - loss: 10.2738 - mean_squared_error: 0.6380 - acc: 0.3620 - f1: 0.3036\n",
      "Epoch 387/500\n",
      " - 0s - loss: 10.2430 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3020\n",
      "Epoch 388/500\n",
      " - 0s - loss: 10.2717 - mean_squared_error: 0.6379 - acc: 0.3621 - f1: 0.3082\n",
      "Epoch 389/500\n",
      " - 0s - loss: 10.1963 - mean_squared_error: 0.6332 - acc: 0.3668 - f1: 0.3037\n",
      "Epoch 390/500\n",
      " - 0s - loss: 10.1532 - mean_squared_error: 0.6305 - acc: 0.3695 - f1: 0.3153\n",
      "Epoch 391/500\n",
      " - 0s - loss: 10.1803 - mean_squared_error: 0.6322 - acc: 0.3678 - f1: 0.3080\n",
      "Epoch 392/500\n",
      " - 0s - loss: 10.2426 - mean_squared_error: 0.6361 - acc: 0.3639 - f1: 0.3053\n",
      "Epoch 393/500\n",
      " - 0s - loss: 10.1627 - mean_squared_error: 0.6311 - acc: 0.3689 - f1: 0.3131\n",
      "Epoch 394/500\n",
      " - 0s - loss: 10.2600 - mean_squared_error: 0.6372 - acc: 0.3628 - f1: 0.3024\n",
      "Epoch 395/500\n",
      " - 0s - loss: 10.2368 - mean_squared_error: 0.6357 - acc: 0.3643 - f1: 0.3018\n",
      "Epoch 396/500\n",
      " - 0s - loss: 10.1878 - mean_squared_error: 0.6327 - acc: 0.3673 - f1: 0.3101\n",
      "Epoch 397/500\n",
      " - 0s - loss: 10.2129 - mean_squared_error: 0.6342 - acc: 0.3658 - f1: 0.3078\n",
      "Epoch 398/500\n",
      " - 0s - loss: 10.1865 - mean_squared_error: 0.6326 - acc: 0.3674 - f1: 0.3083\n",
      "Epoch 399/500\n",
      " - 0s - loss: 10.2917 - mean_squared_error: 0.6391 - acc: 0.3609 - f1: 0.2954\n",
      "Epoch 400/500\n",
      " - 0s - loss: 10.2223 - mean_squared_error: 0.6348 - acc: 0.3652 - f1: 0.3072\n",
      "Epoch 401/500\n",
      " - 0s - loss: 10.2821 - mean_squared_error: 0.6385 - acc: 0.3615 - f1: 0.2985\n",
      "Epoch 402/500\n",
      " - 0s - loss: 10.2680 - mean_squared_error: 0.6376 - acc: 0.3624 - f1: 0.3000\n",
      "Epoch 403/500\n",
      " - 0s - loss: 10.3326 - mean_squared_error: 0.6416 - acc: 0.3584 - f1: 0.2904\n",
      "Epoch 404/500\n",
      " - 0s - loss: 10.2283 - mean_squared_error: 0.6352 - acc: 0.3648 - f1: 0.3082\n",
      "Epoch 405/500\n",
      " - 0s - loss: 10.2085 - mean_squared_error: 0.6339 - acc: 0.3661 - f1: 0.3058\n",
      "Epoch 406/500\n",
      " - 0s - loss: 10.0537 - mean_squared_error: 0.6243 - acc: 0.3757 - f1: 0.3182\n",
      "Epoch 407/500\n",
      " - 0s - loss: 10.1915 - mean_squared_error: 0.6329 - acc: 0.3671 - f1: 0.3051\n",
      "Epoch 408/500\n",
      " - 0s - loss: 10.2050 - mean_squared_error: 0.6338 - acc: 0.3662 - f1: 0.3088\n",
      "Epoch 409/500\n",
      " - 0s - loss: 10.1565 - mean_squared_error: 0.6307 - acc: 0.3693 - f1: 0.3135\n",
      "Epoch 410/500\n",
      " - 0s - loss: 10.1552 - mean_squared_error: 0.6306 - acc: 0.3694 - f1: 0.3111\n",
      "Epoch 411/500\n",
      " - 0s - loss: 10.2683 - mean_squared_error: 0.6376 - acc: 0.3624 - f1: 0.2976\n",
      "Epoch 412/500\n",
      " - 0s - loss: 10.2523 - mean_squared_error: 0.6367 - acc: 0.3633 - f1: 0.3018\n",
      "Epoch 413/500\n",
      " - 0s - loss: 10.1725 - mean_squared_error: 0.6317 - acc: 0.3683 - f1: 0.3091\n",
      "Epoch 414/500\n",
      " - 0s - loss: 10.2354 - mean_squared_error: 0.6356 - acc: 0.3644 - f1: 0.3005\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-8b59f4211e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m  \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m  \u001b[0mtrain_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m  \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "accuracy=[]\n",
    "f1_value=[]\n",
    "for train, test in kfold.split(x_train,y_train):\n",
    " model = Sequential()\n",
    " model.add(Dense(175, input_dim=x_train.shape[1], activation='relu'))\n",
    " model.add(Dropout(0.6))\n",
    " model.add(Dense(175, activation='relu'))\n",
    " model.add(Dropout(0.5))\n",
    " model.add(Dense(1, activation='sigmoid'))\n",
    " model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['mse','acc',f1])\n",
    " train=model.fit(x_train[train], y_train[train],epochs=500, verbose=2,batch_size=x_train.shape[0])\n",
    " train_model=model.evaluate(x_train[test],y_train[test],verbose=2)\n",
    " accuracy.append(train_model[2])\n",
    " f1_value.append(train_model[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the training set\n",
      "Accuracy is: 0.5392638038925492\n",
      "F1 is: 0.49795125637735643\n"
     ]
    }
   ],
   "source": [
    "print(\"For the training set\")\n",
    "print(\"Accuracy is: \"+str(np.mean(accuracy)))\n",
    "print(\"F1 is: \"+str(np.mean(f1_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test test\n",
      "Accuracy is: 0.7430774623203645\n",
      "F1 is: 0.8451232763077141\n"
     ]
    }
   ],
   "source": [
    "print(\"For the test test\")\n",
    "test_model=model.evaluate(x_val,y_val,verbose=2)\n",
    "print(\"Accuracy is: \"+str(test_model[2]))\n",
    "print(\"F1 is: \"+ str(test_model[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11410/11410 [==============================] - 1s 49us/step - loss: 439484.7188 - mean_squared_error: 0.2226 - acc: 0.6917 - f1: 0.8107 - precision: 0.7258 - recall: 0.9180\n",
      "Epoch 2/10\n",
      "11410/11410 [==============================] - 0s 6us/step - loss: 0.6976 - mean_squared_error: 0.2492 - acc: 0.7191 - f1: 0.8366 - precision: 0.7192 - recall: 0.9998\n",
      "Epoch 3/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6891 - mean_squared_error: 0.2457 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 4/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6816 - mean_squared_error: 0.2424 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 5/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6748 - mean_squared_error: 0.2393 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 6/10\n",
      "11410/11410 [==============================] - 0s 6us/step - loss: 0.6687 - mean_squared_error: 0.2365 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 7/10\n",
      "11410/11410 [==============================] - 0s 6us/step - loss: 0.6630 - mean_squared_error: 0.2338 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 8/10\n",
      "11410/11410 [==============================] - 0s 6us/step - loss: 0.6578 - mean_squared_error: 0.2313 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 9/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6529 - mean_squared_error: 0.2291 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n",
      "Epoch 10/10\n",
      "11410/11410 [==============================] - 0s 5us/step - loss: 0.6485 - mean_squared_error: 0.2270 - acc: 0.7191 - f1: 0.8366 - precision: 0.7191 - recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(175, input_dim=x_train.shape[1], activation='relu',activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.080, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['mse','acc',f1,precision,recall])\n",
    "train=model.fit(x_train, y_train,epochs=10, verbose=1,class_weight=class_weights_values,batch_size=x_train.shape[0])\n",
    "train_model=model.evaluate(x_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7191060473373541\n",
      "Recall: 1.0\n",
      "F1: 0.82643346677842\n",
      "Accuracy: 0.7191060473373541\n"
     ]
    }
   ],
   "source": [
    "#For training\n",
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[4]))\n",
    "print(\"Recall: \"+str(train_model[5]))\n",
    "print(\"F1: \"+str(train_model[3]))\n",
    "print(\"Accuracy: \"+str(train_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model.evaluate(x_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7430774623203645\n",
      "Recall: 1.0\n",
      "F1: 0.8451232763077141\n",
      "Accuracy: 0.7430774623203645\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[4]))\n",
    "print(\"Recall: \"+str(val_model[5]))\n",
    "print(\"F1: \"+str(val_model[3]))\n",
    "print(\"Accuracy: \"+str(val_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11410, 1, 51)\n"
     ]
    }
   ],
   "source": [
    "#using LSTM\n",
    "new_x_train=x_train\n",
    "new_x_train= new_x_train.reshape((new_x_train.shape[0],1,new_x_train.shape[1]))\n",
    "print(new_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2853, 1, 51)\n"
     ]
    }
   ],
   "source": [
    "new_x_val=x_val\n",
    "new_x_val= new_x_val.reshape((new_x_val.shape[0],1,new_x_val.shape[1]))\n",
    "print(new_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11410 samples, validate on 2853 samples\n",
      "Epoch 1/60\n",
      " - 2s - loss: 1.3939 - mean_squared_error: 0.3663 - acc: 0.3975 - f1: 0.3958 - precision: 0.7095 - recall: 0.2745 - val_loss: 0.9217 - val_mean_squared_error: 0.3237 - val_acc: 0.4791 - val_f1: 0.5900 - val_precision: 0.7108 - val_recall: 0.5042\n",
      "Epoch 2/60\n",
      " - 0s - loss: 1.1471 - mean_squared_error: 0.3231 - acc: 0.4938 - f1: 0.5842 - precision: 0.7136 - recall: 0.4945 - val_loss: 0.7095 - val_mean_squared_error: 0.2549 - val_acc: 0.6200 - val_f1: 0.7517 - val_precision: 0.7306 - val_recall: 0.7741\n",
      "Epoch 3/60\n",
      " - 0s - loss: 0.9488 - mean_squared_error: 0.2847 - acc: 0.5767 - f1: 0.6940 - precision: 0.7226 - recall: 0.6676 - val_loss: 0.6105 - val_mean_squared_error: 0.2093 - val_acc: 0.7392 - val_f1: 0.8499 - val_precision: 0.7424 - val_recall: 0.9939\n",
      "Epoch 4/60\n",
      " - 0s - loss: 0.8846 - mean_squared_error: 0.2679 - acc: 0.6215 - f1: 0.7464 - precision: 0.7202 - recall: 0.7745 - val_loss: 0.5853 - val_mean_squared_error: 0.1975 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 5/60\n",
      " - 0s - loss: 0.8222 - mean_squared_error: 0.2529 - acc: 0.6504 - f1: 0.7760 - precision: 0.7196 - recall: 0.8419 - val_loss: 0.5826 - val_mean_squared_error: 0.1959 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 6/60\n",
      " - 0s - loss: 0.7983 - mean_squared_error: 0.2482 - acc: 0.6552 - f1: 0.7817 - precision: 0.7175 - recall: 0.8586 - val_loss: 0.5818 - val_mean_squared_error: 0.1951 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 7/60\n",
      " - 0s - loss: 0.7905 - mean_squared_error: 0.2436 - acc: 0.6670 - f1: 0.7921 - precision: 0.7187 - recall: 0.8820 - val_loss: 0.5807 - val_mean_squared_error: 0.1943 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 8/60\n",
      " - 0s - loss: 0.7570 - mean_squared_error: 0.2372 - acc: 0.6770 - f1: 0.7997 - precision: 0.7218 - recall: 0.8963 - val_loss: 0.5778 - val_mean_squared_error: 0.1935 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 9/60\n",
      " - 0s - loss: 0.7592 - mean_squared_error: 0.2390 - acc: 0.6768 - f1: 0.7996 - precision: 0.7215 - recall: 0.8966 - val_loss: 0.5772 - val_mean_squared_error: 0.1928 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 10/60\n",
      " - 0s - loss: 0.7372 - mean_squared_error: 0.2337 - acc: 0.6814 - f1: 0.8041 - precision: 0.7209 - recall: 0.9090 - val_loss: 0.5750 - val_mean_squared_error: 0.1922 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 11/60\n",
      " - 0s - loss: 0.7327 - mean_squared_error: 0.2340 - acc: 0.6788 - f1: 0.8027 - precision: 0.7189 - recall: 0.9085 - val_loss: 0.5728 - val_mean_squared_error: 0.1914 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 12/60\n",
      " - 0s - loss: 0.7063 - mean_squared_error: 0.2282 - acc: 0.6885 - f1: 0.8092 - precision: 0.7231 - recall: 0.9186 - val_loss: 0.5713 - val_mean_squared_error: 0.1908 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 13/60\n",
      " - 0s - loss: 0.7035 - mean_squared_error: 0.2273 - acc: 0.6878 - f1: 0.8099 - precision: 0.7204 - recall: 0.9247 - val_loss: 0.5698 - val_mean_squared_error: 0.1904 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 14/60\n",
      " - 0s - loss: 0.6974 - mean_squared_error: 0.2272 - acc: 0.6876 - f1: 0.8098 - precision: 0.7202 - recall: 0.9248 - val_loss: 0.5682 - val_mean_squared_error: 0.1899 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 15/60\n",
      " - 0s - loss: 0.6824 - mean_squared_error: 0.2240 - acc: 0.6892 - f1: 0.8106 - precision: 0.7214 - recall: 0.9250 - val_loss: 0.5668 - val_mean_squared_error: 0.1893 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 16/60\n",
      " - 0s - loss: 0.6847 - mean_squared_error: 0.2242 - acc: 0.6885 - f1: 0.8108 - precision: 0.7199 - recall: 0.9280 - val_loss: 0.5653 - val_mean_squared_error: 0.1887 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 17/60\n",
      " - 0s - loss: 0.6630 - mean_squared_error: 0.2196 - acc: 0.6943 - f1: 0.8151 - precision: 0.7213 - recall: 0.9370 - val_loss: 0.5643 - val_mean_squared_error: 0.1883 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 18/60\n",
      " - 0s - loss: 0.6675 - mean_squared_error: 0.2215 - acc: 0.6897 - f1: 0.8122 - precision: 0.7191 - recall: 0.9331 - val_loss: 0.5631 - val_mean_squared_error: 0.1880 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 19/60\n",
      " - 0s - loss: 0.6574 - mean_squared_error: 0.2179 - acc: 0.6954 - f1: 0.8159 - precision: 0.7216 - recall: 0.9386 - val_loss: 0.5622 - val_mean_squared_error: 0.1878 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 20/60\n",
      " - 0s - loss: 0.6476 - mean_squared_error: 0.2165 - acc: 0.6966 - f1: 0.8172 - precision: 0.7209 - recall: 0.9432 - val_loss: 0.5618 - val_mean_squared_error: 0.1876 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 21/60\n",
      " - 0s - loss: 0.6427 - mean_squared_error: 0.2164 - acc: 0.6932 - f1: 0.8147 - precision: 0.7201 - recall: 0.9380 - val_loss: 0.5605 - val_mean_squared_error: 0.1870 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 22/60\n",
      " - 0s - loss: 0.6421 - mean_squared_error: 0.2147 - acc: 0.6978 - f1: 0.8180 - precision: 0.7214 - recall: 0.9444 - val_loss: 0.5596 - val_mean_squared_error: 0.1867 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 23/60\n",
      " - 0s - loss: 0.6360 - mean_squared_error: 0.2132 - acc: 0.7022 - f1: 0.8209 - precision: 0.7233 - recall: 0.9489 - val_loss: 0.5588 - val_mean_squared_error: 0.1865 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 24/60\n",
      " - 0s - loss: 0.6304 - mean_squared_error: 0.2116 - acc: 0.7036 - f1: 0.8220 - precision: 0.7233 - recall: 0.9520 - val_loss: 0.5583 - val_mean_squared_error: 0.1863 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 25/60\n",
      " - 0s - loss: 0.6277 - mean_squared_error: 0.2110 - acc: 0.7035 - f1: 0.8222 - precision: 0.7229 - recall: 0.9531 - val_loss: 0.5573 - val_mean_squared_error: 0.1859 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 26/60\n",
      " - 0s - loss: 0.6260 - mean_squared_error: 0.2099 - acc: 0.7034 - f1: 0.8222 - precision: 0.7226 - recall: 0.9537 - val_loss: 0.5567 - val_mean_squared_error: 0.1856 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 27/60\n",
      " - 0s - loss: 0.6286 - mean_squared_error: 0.2115 - acc: 0.7026 - f1: 0.8216 - precision: 0.7225 - recall: 0.9521 - val_loss: 0.5568 - val_mean_squared_error: 0.1857 - val_acc: 0.7431 - val_f1: 0.8526 - val_precision: 0.7431 - val_recall: 1.0000\n",
      "Epoch 28/60\n",
      " - 0s - loss: 0.6202 - mean_squared_error: 0.2095 - acc: 0.7039 - f1: 0.8220 - precision: 0.7241 - recall: 0.9504 - val_loss: 0.5560 - val_mean_squared_error: 0.1853 - val_acc: 0.7427 - val_f1: 0.8524 - val_precision: 0.7430 - val_recall: 0.9995\n",
      "Epoch 29/60\n",
      " - 0s - loss: 0.6193 - mean_squared_error: 0.2084 - acc: 0.7041 - f1: 0.8227 - precision: 0.7229 - recall: 0.9544 - val_loss: 0.5563 - val_mean_squared_error: 0.1855 - val_acc: 0.7431 - val_f1: 0.8525 - val_precision: 0.7432 - val_recall: 0.9995\n",
      "Epoch 30/60\n",
      " - 0s - loss: 0.6199 - mean_squared_error: 0.2093 - acc: 0.6993 - f1: 0.8193 - precision: 0.7213 - recall: 0.9482 - val_loss: 0.5545 - val_mean_squared_error: 0.1847 - val_acc: 0.7427 - val_f1: 0.8523 - val_precision: 0.7432 - val_recall: 0.9991\n",
      "Epoch 31/60\n",
      " - 0s - loss: 0.6124 - mean_squared_error: 0.2063 - acc: 0.7096 - f1: 0.8266 - precision: 0.7243 - recall: 0.9625 - val_loss: 0.5558 - val_mean_squared_error: 0.1853 - val_acc: 0.7431 - val_f1: 0.8525 - val_precision: 0.7434 - val_recall: 0.9991\n",
      "Epoch 32/60\n",
      " - 0s - loss: 0.6094 - mean_squared_error: 0.2051 - acc: 0.7072 - f1: 0.8241 - precision: 0.7254 - recall: 0.9539 - val_loss: 0.5545 - val_mean_squared_error: 0.1848 - val_acc: 0.7431 - val_f1: 0.8524 - val_precision: 0.7438 - val_recall: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      " - 0s - loss: 0.6094 - mean_squared_error: 0.2057 - acc: 0.7055 - f1: 0.8235 - precision: 0.7236 - recall: 0.9555 - val_loss: 0.5545 - val_mean_squared_error: 0.1847 - val_acc: 0.7434 - val_f1: 0.8527 - val_precision: 0.7437 - val_recall: 0.9991\n",
      "Epoch 34/60\n",
      " - 0s - loss: 0.6072 - mean_squared_error: 0.2051 - acc: 0.7089 - f1: 0.8255 - precision: 0.7254 - recall: 0.9576 - val_loss: 0.5539 - val_mean_squared_error: 0.1845 - val_acc: 0.7424 - val_f1: 0.8520 - val_precision: 0.7434 - val_recall: 0.9976\n",
      "Epoch 35/60\n",
      " - 0s - loss: 0.6100 - mean_squared_error: 0.2051 - acc: 0.7080 - f1: 0.8251 - precision: 0.7247 - recall: 0.9578 - val_loss: 0.5525 - val_mean_squared_error: 0.1840 - val_acc: 0.7427 - val_f1: 0.8521 - val_precision: 0.7437 - val_recall: 0.9976\n",
      "Epoch 36/60\n",
      " - 0s - loss: 0.6049 - mean_squared_error: 0.2039 - acc: 0.7093 - f1: 0.8266 - precision: 0.7238 - recall: 0.9634 - val_loss: 0.5533 - val_mean_squared_error: 0.1843 - val_acc: 0.7441 - val_f1: 0.8528 - val_precision: 0.7447 - val_recall: 0.9976\n",
      "Epoch 37/60\n",
      " - 0s - loss: 0.6009 - mean_squared_error: 0.2021 - acc: 0.7089 - f1: 0.8264 - precision: 0.7234 - recall: 0.9636 - val_loss: 0.5529 - val_mean_squared_error: 0.1841 - val_acc: 0.7438 - val_f1: 0.8527 - val_precision: 0.7445 - val_recall: 0.9976\n",
      "Epoch 38/60\n",
      " - 0s - loss: 0.6041 - mean_squared_error: 0.2039 - acc: 0.7064 - f1: 0.8245 - precision: 0.7231 - recall: 0.9589 - val_loss: 0.5517 - val_mean_squared_error: 0.1836 - val_acc: 0.7448 - val_f1: 0.8532 - val_precision: 0.7452 - val_recall: 0.9976\n",
      "Epoch 39/60\n",
      " - 0s - loss: 0.5976 - mean_squared_error: 0.2016 - acc: 0.7131 - f1: 0.8294 - precision: 0.7247 - recall: 0.9694 - val_loss: 0.5537 - val_mean_squared_error: 0.1845 - val_acc: 0.7434 - val_f1: 0.8522 - val_precision: 0.7451 - val_recall: 0.9953\n",
      "Epoch 40/60\n",
      " - 0s - loss: 0.6041 - mean_squared_error: 0.2033 - acc: 0.7083 - f1: 0.8252 - precision: 0.7252 - recall: 0.9571 - val_loss: 0.5528 - val_mean_squared_error: 0.1841 - val_acc: 0.7427 - val_f1: 0.8516 - val_precision: 0.7452 - val_recall: 0.9934\n",
      "Epoch 41/60\n",
      " - 0s - loss: 0.5986 - mean_squared_error: 0.2022 - acc: 0.7082 - f1: 0.8248 - precision: 0.7257 - recall: 0.9551 - val_loss: 0.5516 - val_mean_squared_error: 0.1837 - val_acc: 0.7427 - val_f1: 0.8517 - val_precision: 0.7450 - val_recall: 0.9939\n",
      "Epoch 42/60\n",
      " - 0s - loss: 0.5994 - mean_squared_error: 0.2019 - acc: 0.7123 - f1: 0.8284 - precision: 0.7252 - recall: 0.9658 - val_loss: 0.5516 - val_mean_squared_error: 0.1836 - val_acc: 0.7438 - val_f1: 0.8522 - val_precision: 0.7457 - val_recall: 0.9943\n",
      "Epoch 43/60\n",
      " - 0s - loss: 0.5988 - mean_squared_error: 0.2020 - acc: 0.7112 - f1: 0.8273 - precision: 0.7259 - recall: 0.9616 - val_loss: 0.5520 - val_mean_squared_error: 0.1838 - val_acc: 0.7434 - val_f1: 0.8521 - val_precision: 0.7454 - val_recall: 0.9943\n",
      "Epoch 44/60\n",
      " - 0s - loss: 0.6003 - mean_squared_error: 0.2026 - acc: 0.7102 - f1: 0.8269 - precision: 0.7248 - recall: 0.9625 - val_loss: 0.5523 - val_mean_squared_error: 0.1839 - val_acc: 0.7431 - val_f1: 0.8518 - val_precision: 0.7455 - val_recall: 0.9934\n",
      "Epoch 45/60\n",
      " - 0s - loss: 0.5997 - mean_squared_error: 0.2021 - acc: 0.7109 - f1: 0.8269 - precision: 0.7261 - recall: 0.9600 - val_loss: 0.5517 - val_mean_squared_error: 0.1837 - val_acc: 0.7434 - val_f1: 0.8521 - val_precision: 0.7454 - val_recall: 0.9943\n",
      "Epoch 46/60\n",
      " - 0s - loss: 0.5939 - mean_squared_error: 0.2008 - acc: 0.7109 - f1: 0.8278 - precision: 0.7239 - recall: 0.9665 - val_loss: 0.5498 - val_mean_squared_error: 0.1829 - val_acc: 0.7434 - val_f1: 0.8520 - val_precision: 0.7456 - val_recall: 0.9939\n",
      "Epoch 47/60\n",
      " - 0s - loss: 0.5942 - mean_squared_error: 0.2010 - acc: 0.7092 - f1: 0.8265 - precision: 0.7237 - recall: 0.9633 - val_loss: 0.5502 - val_mean_squared_error: 0.1831 - val_acc: 0.7441 - val_f1: 0.8522 - val_precision: 0.7466 - val_recall: 0.9925\n",
      "Epoch 48/60\n",
      " - 0s - loss: 0.5904 - mean_squared_error: 0.1991 - acc: 0.7130 - f1: 0.8286 - precision: 0.7261 - recall: 0.9647 - val_loss: 0.5507 - val_mean_squared_error: 0.1833 - val_acc: 0.7438 - val_f1: 0.8519 - val_precision: 0.7467 - val_recall: 0.9915\n",
      "Epoch 49/60\n",
      " - 0s - loss: 0.5885 - mean_squared_error: 0.1988 - acc: 0.7137 - f1: 0.8286 - precision: 0.7273 - recall: 0.9627 - val_loss: 0.5479 - val_mean_squared_error: 0.1821 - val_acc: 0.7445 - val_f1: 0.8528 - val_precision: 0.7457 - val_recall: 0.9958\n",
      "Epoch 50/60\n",
      " - 0s - loss: 0.5936 - mean_squared_error: 0.1995 - acc: 0.7141 - f1: 0.8302 - precision: 0.7247 - recall: 0.9716 - val_loss: 0.5507 - val_mean_squared_error: 0.1833 - val_acc: 0.7448 - val_f1: 0.8526 - val_precision: 0.7468 - val_recall: 0.9934\n",
      "Epoch 51/60\n",
      " - 0s - loss: 0.5875 - mean_squared_error: 0.1982 - acc: 0.7166 - f1: 0.8309 - precision: 0.7277 - recall: 0.9682 - val_loss: 0.5503 - val_mean_squared_error: 0.1832 - val_acc: 0.7431 - val_f1: 0.8513 - val_precision: 0.7469 - val_recall: 0.9896\n",
      "Epoch 52/60\n",
      " - 0s - loss: 0.5813 - mean_squared_error: 0.1960 - acc: 0.7167 - f1: 0.8308 - precision: 0.7280 - recall: 0.9673 - val_loss: 0.5485 - val_mean_squared_error: 0.1824 - val_acc: 0.7427 - val_f1: 0.8514 - val_precision: 0.7457 - val_recall: 0.9920\n",
      "Epoch 53/60\n",
      " - 0s - loss: 0.5898 - mean_squared_error: 0.1985 - acc: 0.7133 - f1: 0.8291 - precision: 0.7257 - recall: 0.9667 - val_loss: 0.5496 - val_mean_squared_error: 0.1829 - val_acc: 0.7448 - val_f1: 0.8525 - val_precision: 0.7473 - val_recall: 0.9920\n",
      "Epoch 54/60\n",
      " - 0s - loss: 0.5861 - mean_squared_error: 0.1981 - acc: 0.7157 - f1: 0.8304 - precision: 0.7271 - recall: 0.9678 - val_loss: 0.5480 - val_mean_squared_error: 0.1822 - val_acc: 0.7438 - val_f1: 0.8521 - val_precision: 0.7462 - val_recall: 0.9929\n",
      "Epoch 55/60\n",
      " - 0s - loss: 0.5835 - mean_squared_error: 0.1968 - acc: 0.7163 - f1: 0.8310 - precision: 0.7268 - recall: 0.9701 - val_loss: 0.5493 - val_mean_squared_error: 0.1828 - val_acc: 0.7452 - val_f1: 0.8527 - val_precision: 0.7474 - val_recall: 0.9925\n",
      "Epoch 56/60\n",
      " - 0s - loss: 0.5863 - mean_squared_error: 0.1978 - acc: 0.7160 - f1: 0.8304 - precision: 0.7277 - recall: 0.9667 - val_loss: 0.5496 - val_mean_squared_error: 0.1828 - val_acc: 0.7445 - val_f1: 0.8522 - val_precision: 0.7472 - val_recall: 0.9915\n",
      "Epoch 57/60\n",
      " - 0s - loss: 0.5850 - mean_squared_error: 0.1973 - acc: 0.7169 - f1: 0.8315 - precision: 0.7270 - recall: 0.9710 - val_loss: 0.5487 - val_mean_squared_error: 0.1825 - val_acc: 0.7452 - val_f1: 0.8527 - val_precision: 0.7474 - val_recall: 0.9925\n",
      "Epoch 58/60\n",
      " - 0s - loss: 0.5820 - mean_squared_error: 0.1967 - acc: 0.7176 - f1: 0.8319 - precision: 0.7273 - recall: 0.9715 - val_loss: 0.5493 - val_mean_squared_error: 0.1827 - val_acc: 0.7445 - val_f1: 0.8522 - val_precision: 0.7472 - val_recall: 0.9915\n",
      "Epoch 59/60\n",
      " - 0s - loss: 0.5820 - mean_squared_error: 0.1963 - acc: 0.7177 - f1: 0.8321 - precision: 0.7271 - recall: 0.9725 - val_loss: 0.5477 - val_mean_squared_error: 0.1822 - val_acc: 0.7438 - val_f1: 0.8518 - val_precision: 0.7471 - val_recall: 0.9906\n",
      "Epoch 60/60\n",
      " - 0s - loss: 0.5830 - mean_squared_error: 0.1962 - acc: 0.7167 - f1: 0.8314 - precision: 0.7266 - recall: 0.9716 - val_loss: 0.5490 - val_mean_squared_error: 0.1827 - val_acc: 0.7441 - val_f1: 0.8517 - val_precision: 0.7479 - val_recall: 0.9892\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(175,input_shape=(1,x.shape[1]),return_sequences=True,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#es=EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=2, mode='auto')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['mse','acc',f1,precision,recall])\n",
    "train=model.fit(new_x_train, y_train,epochs=60, verbose=2,class_weight=class_weights_values,batch_size=x_train.shape[0],validation_data=(new_x_val, y_val))\n",
    "train_model=model.evaluate(new_x_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7242916825254375\n",
      "Recall: 0.9907047804983743\n",
      "F1: 0.8270446840866317\n",
      "Accuracy: 0.7234005258649614\n"
     ]
    }
   ],
   "source": [
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[4]))\n",
    "print(\"Recall: \"+str(train_model[5]))\n",
    "print(\"F1: \"+str(train_model[3]))\n",
    "print(\"Accuracy: \"+str(train_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model.evaluate(new_x_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7481575139229899\n",
      "Recall: 0.989601422726711\n",
      "F1: 0.8444051558704824\n",
      "Accuracy: 0.7441289870311952\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[4]))\n",
    "print(\"Recall: \"+str(val_model[5]))\n",
    "print(\"F1: \"+str(val_model[3]))\n",
    "print(\"Accuracy: \"+str(val_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 1200\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(data_train['sentences'])\n",
    "sequences = tokenizer.texts_to_sequences(data_train['sentences'])\n",
    "data_words_train = pad_sequences(sequences, maxlen=50)\n",
    "#data_words_train=np.append(data_words_train, tagm,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 3s - loss: 0.6863 - mean_squared_error: 0.2466 - acc: 0.5735 - f1: 0.6872 - precision: 0.7271 - recall: 0.6514\n",
      "Epoch 2/30\n",
      " - 1s - loss: 0.7852 - mean_squared_error: 0.2345 - acc: 0.7200 - f1: 0.8369 - precision: 0.7200 - recall: 0.9990\n",
      "Epoch 3/30\n",
      " - 1s - loss: 0.6080 - mean_squared_error: 0.2084 - acc: 0.7243 - f1: 0.8380 - precision: 0.7255 - recall: 0.9918\n",
      "Epoch 4/30\n",
      " - 1s - loss: 0.5732 - mean_squared_error: 0.1933 - acc: 0.7232 - f1: 0.8376 - precision: 0.7244 - recall: 0.9928\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.5705 - mean_squared_error: 0.1922 - acc: 0.7247 - f1: 0.8382 - precision: 0.7259 - recall: 0.9917\n",
      "Epoch 6/30\n",
      " - 1s - loss: 0.5664 - mean_squared_error: 0.1907 - acc: 0.7258 - f1: 0.8387 - precision: 0.7267 - recall: 0.9916\n",
      "Epoch 7/30\n",
      " - 1s - loss: 0.5647 - mean_squared_error: 0.1899 - acc: 0.7266 - f1: 0.8390 - precision: 0.7276 - recall: 0.9907\n",
      "Epoch 8/30\n",
      " - 1s - loss: 0.5610 - mean_squared_error: 0.1886 - acc: 0.7272 - f1: 0.8393 - precision: 0.7279 - recall: 0.9911\n",
      "Epoch 9/30\n",
      " - 1s - loss: 0.5574 - mean_squared_error: 0.1870 - acc: 0.7280 - f1: 0.8397 - precision: 0.7288 - recall: 0.9904\n",
      "Epoch 10/30\n",
      " - 1s - loss: 0.5539 - mean_squared_error: 0.1857 - acc: 0.7288 - f1: 0.8401 - precision: 0.7294 - recall: 0.9902\n",
      "Epoch 11/30\n",
      " - 1s - loss: 0.5501 - mean_squared_error: 0.1842 - acc: 0.7305 - f1: 0.8409 - precision: 0.7306 - recall: 0.9904\n",
      "Epoch 12/30\n",
      " - 1s - loss: 0.5463 - mean_squared_error: 0.1827 - acc: 0.7303 - f1: 0.8407 - precision: 0.7307 - recall: 0.9899\n",
      "Epoch 13/30\n",
      " - 1s - loss: 0.5403 - mean_squared_error: 0.1805 - acc: 0.7308 - f1: 0.8408 - precision: 0.7315 - recall: 0.9884\n",
      "Epoch 14/30\n",
      " - 1s - loss: 0.5352 - mean_squared_error: 0.1785 - acc: 0.7316 - f1: 0.8412 - precision: 0.7321 - recall: 0.9885\n",
      "Epoch 15/30\n",
      " - 1s - loss: 0.5300 - mean_squared_error: 0.1766 - acc: 0.7323 - f1: 0.8414 - precision: 0.7329 - recall: 0.9876\n",
      "Epoch 16/30\n",
      " - 1s - loss: 0.5270 - mean_squared_error: 0.1751 - acc: 0.7344 - f1: 0.8420 - precision: 0.7356 - recall: 0.9844\n",
      "Epoch 17/30\n",
      " - 1s - loss: 0.5219 - mean_squared_error: 0.1738 - acc: 0.7340 - f1: 0.8422 - precision: 0.7345 - recall: 0.9868\n",
      "Epoch 18/30\n",
      " - 1s - loss: 0.5241 - mean_squared_error: 0.1730 - acc: 0.7457 - f1: 0.8470 - precision: 0.7467 - recall: 0.9784\n",
      "Epoch 19/30\n",
      " - 1s - loss: 0.5518 - mean_squared_error: 0.1843 - acc: 0.7337 - f1: 0.8425 - precision: 0.7332 - recall: 0.9900\n",
      "Epoch 20/30\n",
      " - 1s - loss: 0.5675 - mean_squared_error: 0.1910 - acc: 0.7656 - f1: 0.8468 - precision: 0.7987 - recall: 0.9012\n",
      "Epoch 21/30\n",
      " - 1s - loss: 0.5159 - mean_squared_error: 0.1722 - acc: 0.7396 - f1: 0.8448 - precision: 0.7392 - recall: 0.9857\n",
      "Epoch 22/30\n",
      " - 1s - loss: 0.5061 - mean_squared_error: 0.1659 - acc: 0.7621 - f1: 0.8530 - precision: 0.7677 - recall: 0.9597\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.4970 - mean_squared_error: 0.1651 - acc: 0.7472 - f1: 0.8479 - precision: 0.7473 - recall: 0.9798\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.4910 - mean_squared_error: 0.1603 - acc: 0.7672 - f1: 0.8536 - precision: 0.7790 - recall: 0.9441\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.4855 - mean_squared_error: 0.1606 - acc: 0.7556 - f1: 0.8518 - precision: 0.7550 - recall: 0.9771\n",
      "Epoch 26/30\n",
      " - 1s - loss: 0.4822 - mean_squared_error: 0.1566 - acc: 0.7791 - f1: 0.8572 - precision: 0.8009 - recall: 0.9220\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.4804 - mean_squared_error: 0.1594 - acc: 0.7574 - f1: 0.8535 - precision: 0.7545 - recall: 0.9823\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.4788 - mean_squared_error: 0.1549 - acc: 0.7872 - f1: 0.8585 - precision: 0.8226 - recall: 0.8976\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.4773 - mean_squared_error: 0.1588 - acc: 0.7605 - f1: 0.8555 - precision: 0.7554 - recall: 0.9862\n",
      "Epoch 30/30\n",
      " - 1s - loss: 0.4694 - mean_squared_error: 0.1513 - acc: 0.7923 - f1: 0.8617 - precision: 0.8266 - recall: 0.8999\n"
     ]
    }
   ],
   "source": [
    "#using LSTM for word embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(1200, 100, input_length=50))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#es=EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=2, mode='auto')\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['mse','acc',f1,precision,recall])\n",
    "train=model.fit(data_words_train, y_train,epochs=30, verbose=2,class_weight=class_weights_values,batch_size=x_train.shape[0])\n",
    "train_model=model.evaluate(data_words_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7594832291632342\n",
      "Recall: 0.9853250294584229\n",
      "F1: 0.8501454054734667\n",
      "Accuracy: 0.7707274320353341\n"
     ]
    }
   ],
   "source": [
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[4]))\n",
    "print(\"Recall: \"+str(train_model[5]))\n",
    "print(\"F1: \"+str(train_model[3]))\n",
    "print(\"Accuracy: \"+str(train_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 1200\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(data_val['sentences'])\n",
    "sequences = tokenizer.texts_to_sequences(data_val['sentences'])\n",
    "data_words_val = pad_sequences(sequences, maxlen=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model.evaluate(data_words_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation \n",
      "\n",
      "Precision: 0.7501297164205664\n",
      "Recall: 0.9583619482426153\n",
      "F1: 0.8333367870182394\n",
      "Accuracy: 0.7308096740273397\n"
     ]
    }
   ],
   "source": [
    "print(\"For validation \\n\")\n",
    "print(\"Precision: \"+str(val_model[4]))\n",
    "print(\"Recall: \"+str(val_model[5]))\n",
    "print(\"F1: \"+str(val_model[3]))\n",
    "print(\"Accuracy: \"+str(val_model[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "11410/11410 [==============================] - 14s 1ms/step - loss: 0.5716 - acc: 0.7208 - f1: 0.8301 - precision: 0.7285 - recall: 0.9733\n",
      "Epoch 2/3\n",
      "11410/11410 [==============================] - 12s 1ms/step - loss: 0.5281 - acc: 0.7473 - f1: 0.8401 - precision: 0.7644 - recall: 0.9400\n",
      "Epoch 3/3\n",
      "11410/11410 [==============================] - 12s 1ms/step - loss: 0.5078 - acc: 0.7630 - f1: 0.8480 - precision: 0.7773 - recall: 0.9401\n"
     ]
    }
   ],
   "source": [
    "#Using CNN for word embeddings\n",
    "model_conv = Sequential()\n",
    "model_conv.add(Embedding(vocabulary_size, 100, input_length=50))\n",
    "model_conv.add(Dropout(0.5))\n",
    "model_conv.add(Conv1D(175, 5, activation='relu'))\n",
    "model_conv.add(MaxPooling1D(pool_size=4))\n",
    "model_conv.add(LSTM(175,activation='relu'))\n",
    "model_conv.add(Dense(1, activation='sigmoid'))\n",
    "model_conv.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy',f1,precision,recall])\n",
    "train=model_conv.fit(data_words_train, y_train, epochs=3,class_weight=class_weights_values)\n",
    "train_model=model_conv.evaluate(data_words_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training \n",
      "\n",
      "Precision: 0.7593991969156223\n",
      "Recall: 0.973009341354437\n",
      "F1: 0.8463087762060341\n",
      "Accuracy: 0.7668711656023807\n"
     ]
    }
   ],
   "source": [
    "print(\"For training \\n\")\n",
    "print(\"Precision: \"+str(train_model[3]))\n",
    "print(\"Recall: \"+str(train_model[4]))\n",
    "print(\"F1: \"+str(train_model[2]))\n",
    "print(\"Accuracy: \"+str(train_model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model=model_conv.evaluate(data_words_val,y_val,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing \n",
      "\n",
      "Precision: 0.7463187756891047\n",
      "Recall: 0.9503596593654243\n",
      "F1: 0.8280860715024395\n",
      "Accuracy: 0.722397476340694\n"
     ]
    }
   ],
   "source": [
    "print(\"For testing \\n\")\n",
    "print(\"Precision: \"+str(val_model[3]))\n",
    "print(\"Recall: \"+str(val_model[4]))\n",
    "print(\"F1: \"+str(val_model[2]))\n",
    "print(\"Accuracy: \"+str(val_model[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
