{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from keras.layers import Embedding, Input, Dense, Dropout, Concatenate, Activation, Conv1D, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from functions import balance_data, tokenize_and_transform, embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "\n",
    "num_words = 100000\n",
    "\n",
    "max_len = 10514\n",
    "\n",
    "dim = 200\n",
    "\n",
    "#Either 'glove' or 'w2v'\n",
    "embedding_type = 'w2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/task-1/task1.train.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "docs = []\n",
    "labels = []\n",
    "for line in lines:\n",
    "    line = re.split(r'\\t+', line)\n",
    "    docs.append(line[0])\n",
    "    label = 0\n",
    "    if line[2].strip() == 'non-propaganda':\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    labels.append(label)\n",
    "    \n",
    "docs, labels = balance_data(docs, labels)\n",
    "  \n",
    "docs = [text_to_word_sequence(doc) for doc in docs]\n",
    "lens = [len(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, word_index = tokenize_and_transform(docs, num_words, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating W2V Embedding\n"
     ]
    }
   ],
   "source": [
    "#Prep NN Input\n",
    "\n",
    "matrix = embed_matrix(embedding_type, word_index, dim)\n",
    "\n",
    "seq_input = Input(shape = (max_len,), dtype = 'int32')\n",
    "\n",
    "embedding = Embedding(len(word_index) + 1, \n",
    "                      dim, \n",
    "                      weights = [matrix], \n",
    "                      input_length = max_len, \n",
    "                      trainable = True)\n",
    "\n",
    "embedded_seq = embedding(seq_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4760 samples, validate on 2040 samples\n",
      "Epoch 1/2\n",
      "4760/4760 [==============================] - 475s 100ms/step - loss: 0.6773 - acc: 0.6013 - val_loss: 0.5465 - val_acc: 0.7603\n",
      "Epoch 2/2\n",
      "4760/4760 [==============================] - 458s 96ms/step - loss: 0.5550 - acc: 0.7168 - val_loss: 0.4532 - val_acc: 0.7931\n"
     ]
    }
   ],
   "source": [
    "x = Conv1D(filters = 200, \n",
    "            kernel_size = 2, \n",
    "            padding = 'valid', \n",
    "            activation = 'relu', \n",
    "            strides = 1)(embedded_seq)\n",
    "\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "\n",
    "preds = Dense(1, activation = 'sigmoid',\n",
    "              kernel_initializer = 'normal')(x)\n",
    "\n",
    "model = Model(seq_input, preds)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "               optimizer = 'adam', \n",
    "               metrics = ['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "           epochs = 2, \n",
    "           validation_split = 0.3,\n",
    "           shuffle = True, \n",
    "           batch_size = 50, \n",
    "           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1200 samples\n",
      "Epoch 1/2\n",
      "6800/6800 [==============================] - 1346s 198ms/step - loss: 0.5532 - acc: 0.7096 - val_loss: 0.3742 - val_acc: 0.8208\n",
      "Epoch 2/2\n",
      "6800/6800 [==============================] - 1358s 200ms/step - loss: 0.3553 - acc: 0.8428 - val_loss: 0.2802 - val_acc: 0.8808\n"
     ]
    }
   ],
   "source": [
    "bigram = Conv1D(filters = 200, \n",
    "                kernel_size = 2, \n",
    "                padding = 'valid', \n",
    "                activation = 'relu', \n",
    "                strides = 1)(embedded_seq)\n",
    "\n",
    "bigram = GlobalMaxPooling1D()(bigram)\n",
    "\n",
    "trigram = Conv1D(filters = 200, \n",
    "                 kernel_size = 3, \n",
    "                 padding = 'valid', \n",
    "                 activation = 'relu', \n",
    "                 strides = 1)(embedded_seq)\n",
    "\n",
    "trigram = GlobalMaxPooling1D()(trigram)\n",
    "\n",
    "x_combo = Concatenate(axis = 1)([bigram, trigram])\n",
    "\n",
    "x_combo = Dense(64, activation = 'relu')(x_combo)\n",
    "\n",
    "x_combo = Dropout(0.5)(x_combo)\n",
    "\n",
    "preds_combo = Dense(1, activation = 'sigmoid',\n",
    "              kernel_initializer = 'normal')(x_combo)\n",
    "\n",
    "model_combo = Model(seq_input, preds_combo)\n",
    "\n",
    "model_combo.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = 'adam', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "combo_history = model_combo.fit(X_train, y_train, \n",
    "          epochs = 2, \n",
    "          validation_data = (X_test, y_test), \n",
    "          shuffle = True, \n",
    "          batch_size = 50, \n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model:\n",
      "Precision: 0.777947932618683\n",
      "Recall: 0.8424543946932007\n",
      "F1 Score: 0.8089171974522293\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = [0 if y < 0.5 else 1 for y in y_pred]\n",
    "\n",
    "print(\"Simple Model:\")\n",
    "print(\"Precision: %s\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall: %s\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 Score: %s\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Model:\n",
      "Precision: 0.8833333333333333\n",
      "Recall: 0.87893864013267\n",
      "F1 Score: 0.8811305070656691\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_combo.predict(X_test)\n",
    "\n",
    "y_pred = [0 if y < 0.5 else 1 for y in y_pred]\n",
    "\n",
    "print(\"Complex Model:\")\n",
    "print(\"Precision: %s\" % precision_score(y_test, y_pred))\n",
    "print(\"Recall: %s\" % recall_score(y_test, y_pred))\n",
    "print(\"F1 Score: %s\" % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
